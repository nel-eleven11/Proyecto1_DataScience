{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1fe888",
   "metadata": {},
   "source": [
    "# Carga de Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68500dc5",
   "metadata": {},
   "source": [
    "## .xls / HTML a .csv\n",
    "Los datos del Mineduc se exportan como archivos .xls, realmente teniendo contenido de HTML. Debido a eso, debemos de parsear el archivo HTML e identificar la tabla correcta que contiene los datos. Luego, podemos exportar los datos a su archivo .csv correspondiente, utilizando el valor de la columna 'Departamento' para nombrarlo. Adicionalmente, los archivos utilizan un encoding diferente al estándar utf-8, por lo cual vamos a especificarlo al momento de leer los archivos HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a36f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single file test successful!\n",
      "\n",
      "============================================================\n",
      "PROCESSING ALL FILES\n",
      "============================================================\n",
      "Found 23 .xls files to process\n",
      "  ✅ Processed establecimiento (12).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (18).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (14).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (10).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (5).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento.xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (11).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (22).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (9).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (3).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (13).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (21).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (17).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (20).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (19).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (16).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (6).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (4).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (2).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (1).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (15).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (8).xls: Created 1 CSVs.\n",
      "  ✅ Processed establecimiento (7).xls: Created 1 CSVs.\n",
      "\n",
      "============================================================\n",
      "PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total files: 23\n",
      "✅ Successful: 23\n",
      "❌ Failed: 0\n",
      "\n",
      "✅ No duplicate departamentos found\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_html_excel_file(file_path):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    try:\n",
    "        tables = pd.read_html(str(file_path), encoding=\"iso-8859-1\")\n",
    "\n",
    "        if not tables:\n",
    "            return {\"success\": False, \"error\": \"No tables found in HTML\"}\n",
    "\n",
    "        required_headers = [\"CODIGO\", \"DISTRITO\", \"DEPARTAMENTO\", \"MUNICIPIO\"]\n",
    "        target_table = None\n",
    "        target_index = None\n",
    "\n",
    "        for i, df in enumerate(tables):\n",
    "            df_columns_upper = [str(col).upper().strip() for col in df.columns]\n",
    "            if all(header in df_columns_upper for header in required_headers):\n",
    "                target_table = df\n",
    "                target_index = i\n",
    "                break\n",
    "            else:\n",
    "                if len(df) > 0:\n",
    "                    first_row_upper = [\n",
    "                        str(cell).upper().strip() for cell in df.iloc[0]\n",
    "                    ]\n",
    "                    if all(header in first_row_upper for header in required_headers):\n",
    "                        df.columns = df.iloc[0]\n",
    "                        df = df.drop(df.index[0]).reset_index(drop=True)\n",
    "                        target_table = df\n",
    "                        target_index = i\n",
    "                        break\n",
    "\n",
    "        if target_table is None:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"No table found with required headers.\",\n",
    "            }\n",
    "\n",
    "        target_table = target_table.dropna(how=\"all\")\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": target_table,\n",
    "            \"table_index\": target_index,\n",
    "            \"total_tables\": len(tables),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def sanitize_filename(text):\n",
    "    filename = text.lower().replace(\" \", \"_\")\n",
    "    return re.sub(r\"[^\\w_.]\", \"\", filename)\n",
    "\n",
    "\n",
    "def process_html_files_directory(input_dir, output_dir):\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = list(input_path.glob(\"*.xls\"))\n",
    "\n",
    "    print(f\"Found {len(files)} .xls files to process\")\n",
    "\n",
    "    successful_files = []\n",
    "    failed_files = []\n",
    "    all_departamentos = defaultdict(list)\n",
    "\n",
    "    for file_path in files:\n",
    "        result = parse_html_excel_file(file_path)\n",
    "\n",
    "        if result[\"success\"]:\n",
    "            df = result[\"data\"]\n",
    "\n",
    "            departamentos = []\n",
    "            for departamento, group in df.groupby(\"DEPARTAMENTO\"):\n",
    "                filename = f\"datos_{sanitize_filename(departamento)}.csv\"\n",
    "\n",
    "                output_file = output_path / filename\n",
    "                group.to_csv(output_file, index=False)\n",
    "\n",
    "                departamentos.append(\n",
    "                    {\"name\": departamento, \"filename\": filename, \"rows\": len(group)}\n",
    "                )\n",
    "\n",
    "                all_departamentos[departamento].append(\n",
    "                    {\n",
    "                        \"source_file\": file_path.name,\n",
    "                        \"csv_file\": filename,\n",
    "                        \"rows\": len(group),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            successful_files.append(\n",
    "                {\n",
    "                    \"file\": file_path.name,\n",
    "                    \"departamentos\": departamentos,\n",
    "                    \"total_rows\": len(df),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(f\"  ✅ Processed {file_path.name}: Created {len(departamentos)} CSVs.\")\n",
    "\n",
    "        else:\n",
    "            failed_files.append({\"file\": file_path.name, \"error\": result[\"error\"]})\n",
    "            print(f\"  ❌ Failed {file_path.name}: {result['error']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\nTotal files: {len(files)}\")\n",
    "    print(f\"✅ Successful: {len(successful_files)}\")\n",
    "    print(f\"❌ Failed: {len(failed_files)}\")\n",
    "\n",
    "    # The detailed successful/failed files lists will only be printed if there are successful/failed files.\n",
    "    # The summary already gives a count, so the repetition for successful files is removed here.\n",
    "    # The detailed list for failed files remains as it provides useful error messages.\n",
    "    if failed_files:\n",
    "        print(f\"\\n❌ FAILED FILES:\")\n",
    "        for item in failed_files:\n",
    "            print(f\"  - {item['file']}: {item['error']}\")\n",
    "\n",
    "    duplicates = {\n",
    "        name: sources\n",
    "        for name, sources in all_departamentos.items()\n",
    "        if len(sources) > 1\n",
    "    }\n",
    "    if duplicates:\n",
    "        print(f\"\\n⚠️ DUPLICATE DEPARTAMENTOS:\")\n",
    "        for dept_name, sources in duplicates.items():\n",
    "            print(f\"  {dept_name}: appears in {len(sources)} files\")\n",
    "    else:\n",
    "        print(\"\\n✅ No duplicate departamentos found\")\n",
    "\n",
    "\n",
    "test_result = parse_html_excel_file(\"data/raw/establecimiento.xls\")\n",
    "if test_result[\"success\"]:\n",
    "    print(\"\\nSingle file test successful!\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING ALL FILES\")\n",
    "    print(\"=\" * 60)\n",
    "    process_html_files_directory(\"data/raw\", \"data/csv\")\n",
    "else:\n",
    "    print(f\"❌ Single file test failed: {test_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e96a1",
   "metadata": {},
   "source": [
    "## .csv a DataFrames\n",
    "Luego de haber creado los archivos, podemos cargarlos a DataFrames para realizar el análisis necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bd3c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 CSV files\n",
      "Loaded 23 datasets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load all CSV files\n",
    "csv_dir = Path(\"data/csv\")\n",
    "csv_files = list(csv_dir.glob(\"*.csv\"))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "# Load all datasets\n",
    "datasets = {}\n",
    "for csv_file in csv_files:\n",
    "    dataset_name = csv_file.stem\n",
    "    datasets[dataset_name] = pd.read_csv(csv_file)\n",
    "    \n",
    "print(f\"Loaded {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9176a2",
   "metadata": {},
   "source": [
    "# Descripción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad22cb",
   "metadata": {},
   "source": [
    "## Filas y Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09701424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Dataset Shapes:\n",
      "                 dataset  rows  columns\n",
      "8        datos_guatemala  1036       17\n",
      "11  datos_ciudad_capital   864       17\n",
      "3       datos_san_marcos   431       17\n",
      "7        datos_escuintla   393       17\n",
      "5   datos_quetzaltenango   365       17\n",
      "14   datos_chimaltenango   300       17\n",
      "20   datos_suchitepequez   296       17\n",
      "21         datos_jutiapa   296       17\n",
      "15   datos_huehuetenango   295       17\n",
      "2     datos_alta_verapaz   294       17\n",
      "13          datos_izabal   273       17\n",
      "17      datos_retalhuleu   272       17\n",
      "18           datos_peten   270       17\n",
      "1     datos_sacatepequez   208       17\n",
      "16          datos_quiche   184       17\n",
      "0       datos_chiquimula   136       17\n",
      "6       datos_santa_rosa   133       17\n",
      "12          datos_jalapa   121       17\n",
      "22          datos_solola   111       17\n",
      "9      datos_el_progreso    97       17\n",
      "19    datos_baja_verapaz    94       17\n",
      "4           datos_zacapa    70       17\n",
      "10     datos_totonicapan    51       17\n",
      "\n",
      "📈 Summary:\n",
      "Total rows across all datasets: 6,590\n",
      "Average rows per dataset: 287\n",
      "Min/Max rows: 51 / 1036\n"
     ]
    }
   ],
   "source": [
    "shape_info = []\n",
    "for name, df in datasets.items():\n",
    "    shape_info.append({\n",
    "        'dataset': name,\n",
    "        'rows': df.shape[0],\n",
    "        'columns': df.shape[1]\n",
    "    })\n",
    "\n",
    "shape_df = pd.DataFrame(shape_info)\n",
    "print(\"📊 Dataset Shapes:\")\n",
    "print(shape_df.sort_values('rows', ascending=False))\n",
    "\n",
    "print(f\"\\n📈 Summary:\")\n",
    "print(f\"Total rows across all datasets: {shape_df['rows'].sum():,}\")\n",
    "print(f\"Average rows per dataset: {shape_df['rows'].mean():.0f}\")\n",
    "print(f\"Min/Max rows: {shape_df['rows'].min()} / {shape_df['rows'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd8fd4",
   "metadata": {},
   "source": [
    "## Integridad de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5fef65",
   "metadata": {},
   "source": [
    "### Consistencia en Nombres de Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e31a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Standard columns (17):\n",
      "   1. CODIGO\n",
      "   2. DISTRITO\n",
      "   3. DEPARTAMENTO\n",
      "   4. MUNICIPIO\n",
      "   5. ESTABLECIMIENTO\n",
      "   6. DIRECCION\n",
      "   7. TELEFONO\n",
      "   8. SUPERVISOR\n",
      "   9. DIRECTOR\n",
      "  10. NIVEL\n",
      "  11. SECTOR\n",
      "  12. AREA\n",
      "  13. STATUS\n",
      "  14. MODALIDAD\n",
      "  15. JORNADA\n",
      "  16. PLAN\n",
      "  17. DEPARTAMENTAL\n"
     ]
    }
   ],
   "source": [
    "all_columns = []\n",
    "column_consistency = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    columns = list(df.columns)\n",
    "    all_columns.append(columns)\n",
    "    column_consistency[name] = columns\n",
    "\n",
    "first_columns = all_columns[0]\n",
    "all_same = all(columns == first_columns for columns in all_columns)\n",
    "\n",
    "if all_same:\n",
    "    print(f\"\\n✅ Standard columns ({len(first_columns)}):\")\n",
    "    for i, col in enumerate(first_columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "else:\n",
    "    print(\"\\n❌ Column differences found:\")\n",
    "    for name, columns in column_consistency.items():\n",
    "        if columns != first_columns:\n",
    "            print(f\"  {name}: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54d5d4",
   "metadata": {},
   "source": [
    "### Encoding Problemático\n",
    "Como mencionamos anteriormente, el encoding de los archivos originales era distinto de \"utf-8\". Nos dimos cuenta al realizar el análisis sobre el encoding problemático, sin embargo al cambiarlo dentro de la función anterior logramos correr con éxito este análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330170f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ No encoding issues found (char: '�')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "problematic_char = \"�\"\n",
    "all_problematic_samples = defaultdict(list)\n",
    "issue_found = False\n",
    "\n",
    "for dataset_name, df in datasets.items():\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            str_series = df[col].astype(str) \n",
    "            \n",
    "            contains_char_mask = str_series.str.contains(problematic_char, na=False)\n",
    "            \n",
    "            if contains_char_mask.any():\n",
    "                issue_found = True\n",
    "                current_samples = str_series[contains_char_mask].unique().tolist()\n",
    "                for sample_val in current_samples:\n",
    "                    if len(all_problematic_samples[col]) < 5:\n",
    "                        all_problematic_samples[col].append(sample_val)\n",
    "\n",
    "\n",
    "if issue_found:\n",
    "    print(f\"❌ Encoding issues found (char: '{problematic_char}'):\")\n",
    "    sorted_cols_with_issues = sorted(all_problematic_samples.keys()) \n",
    "\n",
    "    for col in sorted_cols_with_issues:\n",
    "        samples = all_problematic_samples[col]\n",
    "        print(f\"  Column '{col}':\")\n",
    "        for val in samples:\n",
    "            print(f\"    • {val}\")\n",
    "else:\n",
    "    print(f\"✅ No encoding issues found (char: '{problematic_char}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d679f59",
   "metadata": {},
   "source": [
    "# Análisis de Variables\n",
    "Las variables que más operaciones de limpieza necesitan son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1129942-f7f7-4b02-898b-85e15159e4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing (%)</th>\n",
       "      <th>unique_values</th>\n",
       "      <th>sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CODIGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590</td>\n",
       "      <td>[20-01-0024-46, 20-01-0029-46, 20-01-0030-46, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISTRITO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620</td>\n",
       "      <td>[20-001, 20-024, 20-027, 99-001, 20-030]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEPARTAMENTO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>[CHIQUIMULA, SACATEPEQUEZ, ALTA VERAPAZ, SAN M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUNICIPIO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>343</td>\n",
       "      <td>[CHIQUIMULA, SAN JOSE LA ARADA, SAN JUAN ERMIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTABLECIMIENTO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3779</td>\n",
       "      <td>[ESCUELA DE CIENCIAS COMERCIALES NOCTURNA, INS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIRECCION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4428</td>\n",
       "      <td>[10A. AVENIDA 3-71 ZONA 1, 2A CALLE ENTRE 11 Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TELEFONO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4208</td>\n",
       "      <td>[79422150.0, 79420395.0, 41942927.0, 79420290....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>598</td>\n",
       "      <td>[CESAR ADALBERTO NOGUERA JACOME, SILVIA MARILE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3860</td>\n",
       "      <td>[HÉCTOR ALIDIO CERON BRENES, ROMEO RIVERA CHAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NIVEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[DIVERSIFICADO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SECTOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[OFICIAL, PRIVADO, COOPERATIVA, MUNICIPAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AREA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[URBANA, RURAL, SIN ESPECIFICAR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>STATUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ABIERTA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MODALIDAD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[MONOLINGUE, BILINGUE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JORNADA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>[NOCTURNA, VESPERTINA, DOBLE, MATUTINA, SIN JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PLAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>[DIARIO(REGULAR), FIN DE SEMANA, A DISTANCIA, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEPARTAMENTAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[CHIQUIMULA, SACATEPÉQUEZ, ALTA VERAPAZ, SAN M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column  missing (%)  unique_values  \\\n",
       "0            CODIGO          0.0           6590   \n",
       "1          DISTRITO          0.0            620   \n",
       "2      DEPARTAMENTO          0.0             23   \n",
       "3         MUNICIPIO          0.0            343   \n",
       "4   ESTABLECIMIENTO          0.0           3779   \n",
       "5         DIRECCION          0.0           4428   \n",
       "6          TELEFONO          0.0           4208   \n",
       "7        SUPERVISOR          0.0            598   \n",
       "8          DIRECTOR          0.0           3860   \n",
       "9             NIVEL          0.0              1   \n",
       "10           SECTOR          0.0              4   \n",
       "11             AREA          0.0              3   \n",
       "12           STATUS          0.0              1   \n",
       "13        MODALIDAD          0.0              2   \n",
       "14          JORNADA          0.0              6   \n",
       "15             PLAN          0.0             12   \n",
       "16    DEPARTAMENTAL          0.0             26   \n",
       "\n",
       "                                        sample_values  \n",
       "0   [20-01-0024-46, 20-01-0029-46, 20-01-0030-46, ...  \n",
       "1            [20-001, 20-024, 20-027, 99-001, 20-030]  \n",
       "2   [CHIQUIMULA, SACATEPEQUEZ, ALTA VERAPAZ, SAN M...  \n",
       "3   [CHIQUIMULA, SAN JOSE LA ARADA, SAN JUAN ERMIT...  \n",
       "4   [ESCUELA DE CIENCIAS COMERCIALES NOCTURNA, INS...  \n",
       "5   [10A. AVENIDA 3-71 ZONA 1, 2A CALLE ENTRE 11 Y...  \n",
       "6   [79422150.0, 79420395.0, 41942927.0, 79420290....  \n",
       "7   [CESAR ADALBERTO NOGUERA JACOME, SILVIA MARILE...  \n",
       "8   [HÉCTOR ALIDIO CERON BRENES, ROMEO RIVERA CHAC...  \n",
       "9                                     [DIVERSIFICADO]  \n",
       "10         [OFICIAL, PRIVADO, COOPERATIVA, MUNICIPAL]  \n",
       "11                   [URBANA, RURAL, SIN ESPECIFICAR]  \n",
       "12                                          [ABIERTA]  \n",
       "13                             [MONOLINGUE, BILINGUE]  \n",
       "14  [NOCTURNA, VESPERTINA, DOBLE, MATUTINA, SIN JO...  \n",
       "15  [DIARIO(REGULAR), FIN DE SEMANA, A DISTANCIA, ...  \n",
       "16  [CHIQUIMULA, SACATEPÉQUEZ, ALTA VERAPAZ, SAN M...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_stats = []\n",
    "\n",
    "for col in first_columns:\n",
    "    col_data = []\n",
    "    for name, df in datasets.items():\n",
    "        if col in df.columns:\n",
    "            series = df[col].astype(str).str.strip()\n",
    "            col_data.extend(series)\n",
    "\n",
    "    series_all = pd.Series(col_data)\n",
    "    n_total = len(series_all)\n",
    "    n_missing = (series_all == \"\").sum() + series_all.isna().sum()\n",
    "    n_unique = series_all.nunique()\n",
    "    \n",
    "    summary_stats.append({\n",
    "        \"column\": col,\n",
    "        \"missing (%)\": round((n_missing / n_total) * 100, 2),\n",
    "        \"unique_values\": n_unique,\n",
    "        \"sample_values\": series_all.dropna().unique()[:5].tolist()\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_stats)\n",
    "df_summary.sort_values(\"missing (%)\", ascending=False, inplace=True)\n",
    "\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8735b0",
   "metadata": {},
   "source": [
    "## Código\n",
    "Este valor parece ser un identificador único, queremos explorar las siguientes propiedades:\n",
    "- Unicidad: Este código es único dentro de su respectivo dataset o todos?\n",
    "- Formato: Es consistente el formato en todos los datasets? Existen errores de digitación?\n",
    "- Valores Faltantes: Existen valores faltantes?\n",
    "- Nos ayuda a identificar únicamente algún otro valor?\n",
    "\n",
    "Debido a esto, queremos realizar los siguientes pasos de limpieza:\n",
    "\n",
    "- Identificar unicidad del código\n",
    "- Identificar Valores Faltantes\n",
    "- Revisar errores de digitación, cómo lo pueden ser whitespaces o formato incongruente\n",
    "- Identificar si nos puede ayudar a identificar otras variables para verificar errores de digitación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a4fee8",
   "metadata": {},
   "source": [
    "## Distrito\n",
    "Este valor parece ser un identificador geográfico, siguiendo un formato XX-YYY. Queremos explorar las siguientes propiedades\n",
    "- Formato: Es consistente el formato?\n",
    "- Valores Faltantes: Existen valores faltantes dentro de los datasets?\n",
    "- Nos ayuda a identificar únicamente algún otro valor?\n",
    "\n",
    "Debido a esto, queremos realizar los siguientes pasos de limpieza:\n",
    "\n",
    "- Identificar valores faltantes\n",
    "- Revisar errores de digitación\n",
    "- Enforzar un formato consistente\n",
    "- Identificar si nos puede ayuda a verificar la consistencia de Municipio o algún otro valor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5415d62",
   "metadata": {},
   "source": [
    "## Departamento\n",
    "\n",
    "Ya que los DataFrames se encuentran divididos por departamento, esta entrada debería ser completamente consistente. Además, podemos proponer los siguientes pasos para una mayor consistencia:\n",
    "\n",
    "- Identificar el valor RAW más común, ya que un error de digitación sería menos frecuente\n",
    "- Tomar ese valor y realizar las siguientes transformaciones\n",
    "    - Conversión a minúsculas\n",
    "    - Reemplazo de espacios por _\n",
    "    - Aplicar a todas las columnas de cada DF individual\n",
    "- Aplicar OHE luego de mergear los DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e2a71",
   "metadata": {},
   "source": [
    "## Municipio\n",
    "\n",
    "Este valor representa la división política a nivel municipal. Dado que se usa como categoría geográfica clave, es esencial asegurar consistencia.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "- Formato: ¿Se encuentra todo en mayúsculas? ¿Hay tildes inconsistentes?\n",
    "- Valores Faltantes: Confirmar si hay celdas vacías o marcadas incorrectamente.\n",
    "- Relación con otros campos: ¿El municipio concuerda con el departamento correspondiente?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Convertir todo el texto a mayúsculas (.str.upper()).\n",
    "- Eliminar espacios extra antes o después (.str.strip()).\n",
    "- Normalizar tildes y caracteres especiales si necesario.\n",
    "- Validar los municipios contra una lista oficial por departamento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddb656",
   "metadata": {},
   "source": [
    "## Establecimiento\n",
    "\n",
    "Nombre propio de la institución educativa. Puede contener muchas variantes tipográficas y estilísticas que dificultan análisis posteriores.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "- Formato: ¿Se mantiene una capitalización consistente?\n",
    "- Valores Faltantes: ¿Hay registros sin nombre?\n",
    "- Redundancia o duplicación: ¿Existen nombres duplicados con leves diferencias?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Capitalizar nombres con .str.title() para uniformidad visual.\n",
    "- Eliminar espacios repetidos entre palabras.\n",
    "- Remover puntuación innecesaria.\n",
    "- Establecer reglas para abreviaciones comunes si se encuentran (ej. \"Inst.\" por \"Instituto\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0133d64-4ad1-4159-83eb-9c65b77ad67f",
   "metadata": {},
   "source": [
    "## DIRECCIÓN\n",
    "\n",
    "Campo libre con alta variabilidad. Las direcciones pueden contener múltiples abreviaturas, puntuación, y errores de digitación.\n",
    "\n",
    "Exploración a realizar:\n",
    "- Formato: ¿Existen patrones comunes? ¿Se usan abreviaturas (CALLE, AV, etc.)?\n",
    "- Valores inconsistentes: ¿Uso indistinto de mayúsculas, puntuación, acentos?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "- Normalizar a mayúsculas (.str.upper()).\n",
    "- Crear reglas de sustitución para abreviaturas frecuentes (ej. AVENIDA → AV.).\n",
    "- Quitar símbolos innecesarios y estandarizar signos de puntuación.\n",
    "- Opcional: usar expresiones regulares para separar partes de la dirección (calle, número, zona, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bff941-e337-4303-aa50-85cb514fc243",
   "metadata": {},
   "source": [
    "## TELÉFONO\n",
    "\n",
    "Campo numérico con alta variabilidad en formato. Puede contener números concatenados, separadores o caracteres no numéricos.\n",
    "\n",
    "Exploración a realizar:\n",
    "- Formato: ¿Todos los valores contienen exactamente 8 dígitos? ¿Hay múltiples números por celda?\n",
    "- Errores: ¿Caracteres no numéricos? ¿Espacios o signos innecesarios?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Remover todos los caracteres no numéricos con re.sub(r\"\\D\", \"\", telefono).\n",
    "- Validar longitud estándar (8 dígitos en Guatemala).\n",
    "- Si hay múltiples números, dividir y elegir el primero o guardarlos como lista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968f088-68f0-45d5-8365-9ab8c5208b4d",
   "metadata": {},
   "source": [
    "## SUPERVISOR\n",
    "\n",
    "Nombre del supervisor responsable. Puede presentar variaciones por uso de tildes, mayúsculas, y errores ortográficos menores.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "- Formato: ¿Mayúsculas/minúsculas inconsistentes?\n",
    "- Duplicación: ¿Un mismo nombre aparece escrito de múltiples formas?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Capitalizar con .str.title() para uniformidad.\n",
    "- Remover espacios dobles y caracteres extraños.\n",
    "- Normalizar tildes si es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67f16-f9a8-4fdc-9a0f-5e188d88a914",
   "metadata": {},
   "source": [
    "## DIRECTOR\n",
    "\n",
    "Similar al campo de supervisor, representa nombres propios con riesgos similares de inconsistencia.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "- Aplicar los mismos criterios que SUPERVISOR.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Igual estrategia de capitalización, limpieza de espacios, y normalización de caracteres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8203578-43ba-44f3-b112-e7e765512022",
   "metadata": {},
   "source": [
    "## NIVEL\n",
    "Este campo tiene un único valor: \"DIVERSIFICADO\".\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "- Verificar que efectivamente todos los valores son iguales.\n",
    "- Confirmar si es útil conservar esta columna.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Si es redundante, considerar eliminarla para evitar ruido en análisis futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b7908-d5b2-4bcf-8dba-479bc1d64b9f",
   "metadata": {},
   "source": [
    "## SECTOR\n",
    "\n",
    "Categoría con pocos valores únicos. Se espera valores como \"OFICIAL\", \"PRIVADO\", etc.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "- ¿Mayúsculas o minúsculas inconsistentes?\n",
    "- ¿Errores ortográficos?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Convertir todo a mayúsculas y eliminar espacios (.str.upper().str.strip()).\n",
    "- Validar los valores contra un conjunto permitido: {OFICIAL, PRIVADO, MUNICIPAL, COOPERATIVA}.\n",
    "- Convertir a tipo Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5b092-16d1-4790-be2e-4976d8533f41",
   "metadata": {},
   "source": [
    "## ÁREA\n",
    "Identifica si la institución está en zona rural o urbana.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "- Confirmar que los valores son: URBANA, RURAL, SIN ESPECIFICAR.\n",
    "- Verificar errores de digitación o combinaciones no válidas.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Uniformar mayúsculas (.str.upper()).\n",
    "- Reemplazar variantes de “sin especificar” por un valor estándar (ej. \"DESCONOCIDO\").\n",
    "- Convertir a Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb68b7",
   "metadata": {},
   "source": [
    "## STATUS\n",
    "Campo con un único valor: \"ABIERTA\".\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "Verificar si realmente todos los valores son iguales.\n",
    "\n",
    "Evaluar su utilidad en análisis futuros.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Eliminar si es redundante (sin variabilidad)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4aaf2",
   "metadata": {},
   "source": [
    "## MODALIDAD\n",
    "Pocos valores únicos: \"MONOLINGUE\", \"BILINGUE\".\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "Verificar mayúsculas y tildes.\n",
    "\n",
    "Validar que no existan variantes escritas incorrectamente.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Uniformar mayúsculas y acentos (.str.upper()).\n",
    "\n",
    "Reemplazar variantes con un mapeo fijo.\n",
    "\n",
    "Convertir a Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c401d",
   "metadata": {},
   "source": [
    "## JORNADA\n",
    "Categoría horaria. Existen valores como “MATUTINA”, “VESPERTINA”, “DOBLE”, “NOCHE”, etc.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "Verificar consistencia de términos.\n",
    "\n",
    "Identificar redundancias o términos similares con diferencias menores.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Normalizar formato (.str.upper().str.strip()).\n",
    "\n",
    "Mapear variantes a un conjunto estándar.\n",
    "\n",
    "Eliminar signos extra o abreviaciones inconsistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070a90f",
   "metadata": {},
   "source": [
    "## PLAN\n",
    "Puede incluir valores con paréntesis, como “DIARIO(REGULAR)”, que dificultan análisis.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "¿Hay signos innecesarios como paréntesis o guiones?\n",
    "\n",
    "¿Hay términos redundantes?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Eliminar paréntesis y su contenido con str.replace(r'\\(.*?\\)', '').\n",
    "\n",
    "Eliminar espacios extra y convertir a mayúsculas.\n",
    "\n",
    "Validar valores contra una lista limpia predefinida.\n",
    "\n",
    "Convertir a Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b50ae",
   "metadata": {},
   "source": [
    "## DEPARTAMENTAL\n",
    "Representa una división regional administrativa.\n",
    "\n",
    "Exploración a realizar:\n",
    "\n",
    "Verificar mayúsculas, errores tipográficos.\n",
    "\n",
    "Confirmar que corresponde con el valor del campo DEPARTAMENTO.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Uniformar texto (.str.upper().str.strip()).\n",
    "\n",
    "Validar contra un listado oficial del MINEDUC.\n",
    "\n",
    "Opcional: cruzar con DEPARTAMENTO para consistencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef7d0f",
   "metadata": {},
   "source": [
    "## Definición de funciones para limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a07e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_establecimiento(df):\n",
    "\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean['ESTABLECIMIENTO'] = (df_clean['ESTABLECIMIENTO']\n",
    "                                  .str.replace('\"\"', '\"', regex=False)\n",
    "                                  .str.replace('\"', '', regex=False))\n",
    "    \n",
    "    print(f\" ESTABLECIMIENTO limpiado: {(df['ESTABLECIMIENTO'] != df_clean['ESTABLECIMIENTO']).sum()} registros corregidos\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def clean_plan(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean['PLAN'] = (df_clean['PLAN']\n",
    "                       .str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
    "                       .str.strip())\n",
    "    \n",
    "    print(f\" PLAN limpiado: {(df['PLAN'] != df_clean['PLAN']).sum()} registros corregidos\")\n",
    "    print(f\"   Valores únicos después de limpieza: {df_clean['PLAN'].unique()}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def clean_telefono(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    def process_phone(phone):\n",
    "        if pd.isna(phone) or phone == '':\n",
    "            return None\n",
    "            \n",
    "        phone_str = str(phone)\n",
    "        \n",
    "        if '-' in phone_str:\n",
    "            phone_str = phone_str.split('-')[0]\n",
    "        \n",
    "        numbers_only = re.sub(r'[^0-9]', '', phone_str)\n",
    "        \n",
    "        if len(numbers_only) == 8:\n",
    "            return numbers_only\n",
    "        elif len(numbers_only) == 7:\n",
    "            if numbers_only[0] in ['3', '4', '5']:\n",
    "                return '0' + numbers_only\n",
    "            else:\n",
    "                return numbers_only\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    df_clean['TELEFONO'] = df_clean['TELEFONO'].apply(process_phone)\n",
    "    \n",
    "    valid_phones = df_clean['TELEFONO'].notna().sum()\n",
    "    total_phones = len(df_clean)\n",
    "    corrected = (df['TELEFONO'].astype(str) != df_clean['TELEFONO'].astype(str)).sum()\n",
    "    \n",
    "    print(f\"TELEFONO limpiado: {corrected} registros corregidos\")\n",
    "    print(f\"   Teléfonos válidos: {valid_phones}/{total_phones} ({valid_phones/total_phones*100:.1f}%)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def apply_basic_cleaning(df):\n",
    "\n",
    "    print(f\"🧹 Limpiando dataset con {len(df)} registros...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean = clean_establecimiento(df_clean)\n",
    "    df_clean = clean_plan(df_clean)\n",
    "    df_clean = clean_telefono(df_clean)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"Limpieza completada\")\n",
    "    \n",
    "    return df_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffb41a",
   "metadata": {},
   "source": [
    "### Generación de encoding categórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202855d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_categorical_encoding(df):\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    categorical_fields = ['SECTOR', 'AREA', 'MODALIDAD', 'JORNADA', 'PLAN']\n",
    "    \n",
    "    print(\"Creando variables dummy...\")\n",
    "    \n",
    "    for field in categorical_fields:\n",
    "        if field in df_encoded.columns:\n",
    "            dummies = pd.get_dummies(df_encoded[field], prefix=field.lower())\n",
    "            df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "            print(f\"{field}: {len(dummies.columns)} categorías\")\n",
    "    \n",
    "    df_encoded['es_publico'] = df_encoded['SECTOR'].isin(['OFICIAL', 'MUNICIPAL']).astype(int)\n",
    "    df_encoded['es_rural'] = (df_encoded['AREA'] == 'RURAL').astype(int)\n",
    "    df_encoded['tiene_telefono'] = df_encoded['TELEFONO'].notna().astype(int)\n",
    "    \n",
    "    print(f\"Variables adicionales: es_publico, es_rural, tiene_telefono\")\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "def clean_and_prepare_dataset(file_path):\n",
    "    print(f\"Procesando: {Path(file_path).name}\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Registros originales: {len(df)}\")\n",
    "\n",
    "    df_clean = apply_basic_cleaning(df)\n",
    "    \n",
    "    df_encoded = create_categorical_encoding(df_clean)\n",
    "    \n",
    "    print(f\"Registros finales: {len(df_encoded)}\")\n",
    "    print(f\"Columnas finales: {len(df_encoded.columns)}\")\n",
    "    \n",
    "    return df_clean, df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62398bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_datasets(input_dir=\"data/csv\", output_dir=\"data/cleaned\"):\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    csv_files = list(input_path.glob(\"*.csv\"))\n",
    "    print(f\"🚀 Procesando {len(csv_files)} archivos CSV...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    all_clean_data = []\n",
    "    all_encoded_data = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df_clean, df_encoded = clean_and_prepare_dataset(csv_file)\n",
    "            \n",
    "            clean_output = output_path / f\"{csv_file.stem}_clean.csv\"\n",
    "            df_clean.to_csv(clean_output, index=False)\n",
    "            \n",
    "            all_clean_data.append(df_clean)\n",
    "            all_encoded_data.append(df_encoded)\n",
    "            \n",
    "            print(f\"Guardado: {clean_output.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {csv_file.name}: {str(e)}\")\n",
    "    \n",
    "    if all_clean_data:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"📊 Creando datasets combinados...\")\n",
    "        \n",
    "        combined_clean = pd.concat(all_clean_data, ignore_index=True)\n",
    "        combined_clean_path = output_path / \"mineduc_combined_clean.csv\"\n",
    "        combined_clean.to_csv(combined_clean_path, index=False)\n",
    "        \n",
    "        combined_encoded = pd.concat(all_encoded_data, ignore_index=True)\n",
    "        combined_encoded_path = output_path / \"mineduc_combined_encoded.csv\"\n",
    "        combined_encoded.to_csv(combined_encoded_path, index=False)\n",
    "        \n",
    "        print(f\"✅ Dataset limpio combinado: {len(combined_clean)} registros\")\n",
    "        print(f\"   📁 {combined_clean_path}\")\n",
    "        print(f\"✅ Dataset codificado combinado: {len(combined_encoded)} registros, {len(combined_encoded.columns)} columnas\")\n",
    "        print(f\"   📁 {combined_encoded_path}\")\n",
    "        \n",
    "        return combined_clean, combined_encoded\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def generate_summary_report(df):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REPORTE FINAL DE DATOS LIMPIOS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Registros totales: {len(df):,}\")\n",
    "    print(f\"Establecimientos únicos: {df['ESTABLECIMIENTO'].nunique():,}\")\n",
    "    print(f\"Municipios únicos: {df['MUNICIPIO'].nunique()}\")\n",
    "    print(f\"Departamentos únicos: {df['DEPARTAMENTO'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nTeléfonos válidos: {df['TELEFONO'].notna().sum():,} ({df['TELEFONO'].notna().mean()*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nDistribución por SECTOR:\")\n",
    "    sector_dist = df['SECTOR'].value_counts()\n",
    "    for sector, count in sector_dist.items():\n",
    "        print(f\"   {sector}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nDistribución por ÁREA:\")\n",
    "    area_dist = df['AREA'].value_counts()\n",
    "    for area, count in area_dist.items():\n",
    "        print(f\"   {area}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nDistribución por MODALIDAD:\")\n",
    "    modalidad_dist = df['MODALIDAD'].value_counts()\n",
    "    for modalidad, count in modalidad_dist.items():\n",
    "        print(f\"   {modalidad}: {count:,} ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be86158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Procesando 23 archivos CSV...\n",
      "======================================================================\n",
      "📂 Procesando: datos_chiquimula.csv\n",
      "   Registros originales: 136\n",
      "🧹 Limpiando dataset con 136 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 17 registros corregidos\n",
      " PLAN limpiado: 104 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 136 registros corregidos\n",
      "   Teléfonos válidos: 0/136 (0.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 6 categorías\n",
      "PLAN: 4 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 136\n",
      "Columnas finales: 38\n",
      "Guardado: datos_chiquimula_clean.csv\n",
      "📂 Procesando: datos_sacatepequez.csv\n",
      "   Registros originales: 208\n",
      "🧹 Limpiando dataset con 208 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 7 registros corregidos\n",
      " PLAN limpiado: 170 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 1 registros corregidos\n",
      "   Teléfonos válidos: 208/208 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 208\n",
      "Columnas finales: 38\n",
      "Guardado: datos_sacatepequez_clean.csv\n",
      "📂 Procesando: datos_alta_verapaz.csv\n",
      "   Registros originales: 294\n",
      "🧹 Limpiando dataset con 294 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 33 registros corregidos\n",
      " PLAN limpiado: 228 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 8 registros corregidos\n",
      "   Teléfonos válidos: 288/294 (98.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 294\n",
      "Columnas finales: 38\n",
      "Guardado: datos_alta_verapaz_clean.csv\n",
      "📂 Procesando: datos_san_marcos.csv\n",
      "   Registros originales: 431\n",
      "🧹 Limpiando dataset con 431 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 142 registros corregidos\n",
      " PLAN limpiado: 365 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 431 registros corregidos\n",
      "   Teléfonos válidos: 1/431 (0.2%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 6 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 431\n",
      "Columnas finales: 39\n",
      "Guardado: datos_san_marcos_clean.csv\n",
      "📂 Procesando: datos_zacapa.csv\n",
      "   Registros originales: 70\n",
      "🧹 Limpiando dataset con 70 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 23 registros corregidos\n",
      " PLAN limpiado: 59 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 0 registros corregidos\n",
      "   Teléfonos válidos: 70/70 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 1 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 4 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 70\n",
      "Columnas finales: 36\n",
      "Guardado: datos_zacapa_clean.csv\n",
      "📂 Procesando: datos_quetzaltenango.csv\n",
      "   Registros originales: 365\n",
      "🧹 Limpiando dataset con 365 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 98 registros corregidos\n",
      " PLAN limpiado: 308 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 0 registros corregidos\n",
      "   Teléfonos válidos: 365/365 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 365\n",
      "Columnas finales: 38\n",
      "Guardado: datos_quetzaltenango_clean.csv\n",
      "📂 Procesando: datos_santa_rosa.csv\n",
      "   Registros originales: 133\n",
      "🧹 Limpiando dataset con 133 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 56 registros corregidos\n",
      " PLAN limpiado: 104 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL' 'MIXTO']\n",
      "TELEFONO limpiado: 133 registros corregidos\n",
      "   Teléfonos válidos: 0/133 (0.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 1 categorías\n",
      "JORNADA: 6 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 133\n",
      "Columnas finales: 37\n",
      "Guardado: datos_santa_rosa_clean.csv\n",
      "📂 Procesando: datos_escuintla.csv\n",
      "   Registros originales: 393\n",
      "🧹 Limpiando dataset con 393 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 75 registros corregidos\n",
      " PLAN limpiado: 303 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 3 registros corregidos\n",
      "   Teléfonos válidos: 391/393 (99.5%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 6 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 393\n",
      "Columnas finales: 39\n",
      "Guardado: datos_escuintla_clean.csv\n",
      "📂 Procesando: datos_guatemala.csv\n",
      "   Registros originales: 1036\n",
      "🧹 Limpiando dataset con 1036 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 118 registros corregidos\n",
      " PLAN limpiado: 778 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'SEMIPRESENCIAL' 'A DISTANCIA'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 11 registros corregidos\n",
      "   Teléfonos válidos: 1031/1036 (99.5%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 1036\n",
      "Columnas finales: 38\n",
      "Guardado: datos_guatemala_clean.csv\n",
      "📂 Procesando: datos_el_progreso.csv\n",
      "   Registros originales: 97\n",
      "🧹 Limpiando dataset con 97 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 12 registros corregidos\n",
      " PLAN limpiado: 77 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 97 registros corregidos\n",
      "   Teléfonos válidos: 1/97 (1.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 1 categorías\n",
      "JORNADA: 4 categorías\n",
      "PLAN: 4 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 97\n",
      "Columnas finales: 35\n",
      "Guardado: datos_el_progreso_clean.csv\n",
      "📂 Procesando: datos_totonicapan.csv\n",
      "   Registros originales: 51\n",
      "🧹 Limpiando dataset con 51 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 28 registros corregidos\n",
      " PLAN limpiado: 44 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'A DISTANCIA' 'SEMIPRESENCIAL' 'FIN DE SEMANA']\n",
      "TELEFONO limpiado: 5 registros corregidos\n",
      "   Teléfonos válidos: 51/51 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 4 categorías\n",
      "PLAN: 4 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 51\n",
      "Columnas finales: 35\n",
      "Guardado: datos_totonicapan_clean.csv\n",
      "📂 Procesando: datos_ciudad_capital.csv\n",
      "   Registros originales: 864\n",
      "🧹 Limpiando dataset con 864 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 133 registros corregidos\n",
      " PLAN limpiado: 638 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'VIRTUAL A DISTANCIA'\n",
      " 'SEMIPRESENCIAL' 'SABATINO']\n",
      "TELEFONO limpiado: 1 registros corregidos\n",
      "   Teléfonos válidos: 864/864 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 3 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 6 categorías\n",
      "PLAN: 6 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 864\n",
      "Columnas finales: 41\n",
      "Guardado: datos_ciudad_capital_clean.csv\n",
      "📂 Procesando: datos_jalapa.csv\n",
      "   Registros originales: 121\n",
      "🧹 Limpiando dataset con 121 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 69 registros corregidos\n",
      " PLAN limpiado: 91 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 1 registros corregidos\n",
      "   Teléfonos válidos: 121/121 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 1 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 4 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 121\n",
      "Columnas finales: 36\n",
      "Guardado: datos_jalapa_clean.csv\n",
      "📂 Procesando: datos_izabal.csv\n",
      "   Registros originales: 273\n",
      "🧹 Limpiando dataset con 273 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 112 registros corregidos\n",
      " PLAN limpiado: 181 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 14 registros corregidos\n",
      "   Teléfonos válidos: 273/273 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 4 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 273\n",
      "Columnas finales: 37\n",
      "Guardado: datos_izabal_clean.csv\n",
      "📂 Procesando: datos_chimaltenango.csv\n",
      "   Registros originales: 300\n",
      "🧹 Limpiando dataset con 300 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 115 registros corregidos\n",
      " PLAN limpiado: 213 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 7 registros corregidos\n",
      "   Teléfonos válidos: 299/300 (99.7%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 6 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 300\n",
      "Columnas finales: 39\n",
      "Guardado: datos_chimaltenango_clean.csv\n",
      "📂 Procesando: datos_huehuetenango.csv\n",
      "   Registros originales: 295\n",
      "🧹 Limpiando dataset con 295 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 93 registros corregidos\n",
      " PLAN limpiado: 227 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'INTERCALADO' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 0 registros corregidos\n",
      "   Teléfonos válidos: 295/295 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 4 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 295\n",
      "Columnas finales: 36\n",
      "Guardado: datos_huehuetenango_clean.csv\n",
      "📂 Procesando: datos_quiche.csv\n",
      "   Registros originales: 184\n",
      "🧹 Limpiando dataset con 184 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 32 registros corregidos\n",
      " PLAN limpiado: 146 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'VIRTUAL A DISTANCIA'\n",
      " 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 1 registros corregidos\n",
      "   Teléfonos válidos: 183/184 (99.5%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 6 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 184\n",
      "Columnas finales: 39\n",
      "Guardado: datos_quiche_clean.csv\n",
      "📂 Procesando: datos_retalhuleu.csv\n",
      "   Registros originales: 272\n",
      "🧹 Limpiando dataset con 272 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 53 registros corregidos\n",
      " PLAN limpiado: 186 registros corregidos\n",
      "   Valores únicos después de limpieza: ['FIN DE SEMANA' 'DIARIO' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA' 'SABATINO' 'DOMINICAL']\n",
      "TELEFONO limpiado: 272 registros corregidos\n",
      "   Teléfonos válidos: 0/272 (0.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 7 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 272\n",
      "Columnas finales: 40\n",
      "Guardado: datos_retalhuleu_clean.csv\n",
      "📂 Procesando: datos_peten.csv\n",
      "   Registros originales: 270\n",
      "🧹 Limpiando dataset con 270 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 104 registros corregidos\n",
      " PLAN limpiado: 197 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 6 registros corregidos\n",
      "   Teléfonos válidos: 267/270 (98.9%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 6 categorías\n",
      "PLAN: 4 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 270\n",
      "Columnas finales: 38\n",
      "Guardado: datos_peten_clean.csv\n",
      "📂 Procesando: datos_baja_verapaz.csv\n",
      "   Registros originales: 94\n",
      "🧹 Limpiando dataset con 94 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 1 registros corregidos\n",
      " PLAN limpiado: 72 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'SEMIPRESENCIAL' 'A DISTANCIA']\n",
      "TELEFONO limpiado: 2 registros corregidos\n",
      "   Teléfonos válidos: 94/94 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 4 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 94\n",
      "Columnas finales: 36\n",
      "Guardado: datos_baja_verapaz_clean.csv\n",
      "📂 Procesando: datos_suchitepequez.csv\n",
      "   Registros originales: 296\n",
      "🧹 Limpiando dataset con 296 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 124 registros corregidos\n",
      " PLAN limpiado: 205 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA' 'SABATINO']\n",
      "TELEFONO limpiado: 296 registros corregidos\n",
      "   Teléfonos válidos: 2/296 (0.7%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 1 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 6 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 296\n",
      "Columnas finales: 38\n",
      "Guardado: datos_suchitepequez_clean.csv\n",
      "📂 Procesando: datos_jutiapa.csv\n",
      "   Registros originales: 296\n",
      "🧹 Limpiando dataset con 296 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 98 registros corregidos\n",
      " PLAN limpiado: 210 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'VIRTUAL A DISTANCIA'\n",
      " 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 296 registros corregidos\n",
      "   Teléfonos válidos: 2/296 (0.7%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 1 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 296\n",
      "Columnas finales: 37\n",
      "Guardado: datos_jutiapa_clean.csv\n",
      "📂 Procesando: datos_solola.csv\n",
      "   Registros originales: 111\n",
      "🧹 Limpiando dataset con 111 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 30 registros corregidos\n",
      " PLAN limpiado: 98 registros corregidos\n",
      "   Valores únicos después de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 0 registros corregidos\n",
      "   Teléfonos válidos: 111/111 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categorías\n",
      "AREA: 2 categorías\n",
      "MODALIDAD: 2 categorías\n",
      "JORNADA: 5 categorías\n",
      "PLAN: 5 categorías\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 111\n",
      "Columnas finales: 37\n",
      "Guardado: datos_solola_clean.csv\n",
      "\n",
      "======================================================================\n",
      "📊 Creando datasets combinados...\n",
      "✅ Dataset limpio combinado: 6590 registros\n",
      "   📁 data/cleaned/mineduc_combined_clean.csv\n",
      "✅ Dataset codificado combinado: 6590 registros, 44 columnas\n",
      "   📁 data/cleaned/mineduc_combined_encoded.csv\n",
      "\n",
      "============================================================\n",
      "REPORTE FINAL DE DATOS LIMPIOS\n",
      "============================================================\n",
      "Registros totales: 6,590\n",
      "Establecimientos únicos: 3,573\n",
      "Municipios únicos: 343\n",
      "Departamentos únicos: 23\n",
      "\n",
      "Teléfonos válidos: 4,917 (74.6%)\n",
      "\n",
      "Distribución por SECTOR:\n",
      "   PRIVADO: 5,409 (82.1%)\n",
      "   OFICIAL: 874 (13.3%)\n",
      "   COOPERATIVA: 213 (3.2%)\n",
      "   MUNICIPAL: 94 (1.4%)\n",
      "\n",
      "Distribución por ÁREA:\n",
      "   URBANA: 5,242 (79.5%)\n",
      "   RURAL: 1,347 (20.4%)\n",
      "   SIN ESPECIFICAR: 1 (0.0%)\n",
      "\n",
      "Distribución por MODALIDAD:\n",
      "   MONOLINGUE: 6,381 (96.8%)\n",
      "   BILINGUE: 209 (3.2%)\n",
      "\n",
      "¡Proceso completado exitosamente!\n",
      "Archivos disponibles en: data/cleaned/\n",
      "- Archivos individuales limpios\n",
      "- mineduc_combined_clean.csv (datos limpios)\n",
      "- mineduc_combined_encoded.csv (con variables dummy)\n"
     ]
    }
   ],
   "source": [
    "df_clean, df_encoded = process_all_datasets()\n",
    "    \n",
    "if df_clean is not None:\n",
    "    generate_summary_report(df_clean)\n",
    "    \n",
    "    print(f\"\\n¡Proceso completado exitosamente!\")\n",
    "    print(f\"Archivos disponibles en: data/cleaned/\")\n",
    "    print(f\"- Archivos individuales limpios\")\n",
    "    print(f\"- mineduc_combined_clean.csv (datos limpios)\")\n",
    "    print(f\"- mineduc_combined_encoded.csv (con variables dummy)\")\n",
    "else:\n",
    "    print(\"No se pudieron procesar los datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac851b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CODIGO DISTRITO DEPARTAMENTO         MUNICIPIO  \\\n",
      "0     20-01-0024-46   20-001   CHIQUIMULA        CHIQUIMULA   \n",
      "1     20-01-0029-46   20-001   CHIQUIMULA        CHIQUIMULA   \n",
      "2     20-01-0030-46   20-001   CHIQUIMULA        CHIQUIMULA   \n",
      "3     20-01-0031-46   20-024   CHIQUIMULA        CHIQUIMULA   \n",
      "4     20-01-0032-46   20-024   CHIQUIMULA        CHIQUIMULA   \n",
      "...             ...      ...          ...               ...   \n",
      "6585  07-19-0034-46   07-015       SOLOLA  SANTIAGO ATITLAN   \n",
      "6586  07-19-0051-46   07-015       SOLOLA  SANTIAGO ATITLAN   \n",
      "6587  07-19-0065-46   07-015       SOLOLA  SANTIAGO ATITLAN   \n",
      "6588  07-19-0103-46   07-027       SOLOLA  SANTIAGO ATITLAN   \n",
      "6589  07-19-2765-46   07-015       SOLOLA  SANTIAGO ATITLAN   \n",
      "\n",
      "                                        ESTABLECIMIENTO  \\\n",
      "0              ESCUELA DE CIENCIAS COMERCIALES NOCTURNA   \n",
      "1     INSTITUTO DIVERSIFICADO ADS. AL INEB 'DR. DAVI...   \n",
      "2     ESCUELA NACIONAL DE MAESTROS DE EDUCACION MUSI...   \n",
      "3     ESCUELA SECUNDARIA PRIVADA MIXTA DE ORIENTE -E...   \n",
      "4                       COLEGIO EVANGÉLICO MIXTO AMIGOS   \n",
      "...                                                 ...   \n",
      "6585                            LICEO CRISTIANO ISRAELÍ   \n",
      "6586                 LICEO INTEGRAL SANTIAGUITO -LINSA-   \n",
      "6587  ESCUELA NORMAL BILINGÜE INTERCULTURAL / KITIJO...   \n",
      "6588      INSTITUTO NACIONAL DE EDUCACIÓN DIVERSIFICADA   \n",
      "6589  ESCUELA NORMAL BILINGÜE INTERCULTURAL / KITIJO...   \n",
      "\n",
      "                                       DIRECCION  TELEFONO  \\\n",
      "0                       10A. AVENIDA 3-71 ZONA 1      None   \n",
      "1         2A CALLE ENTRE 11 Y 12 AVENIDAS ZONA 1      None   \n",
      "2                   2A CALLE Y 12 AVENIDA ZONA 1      None   \n",
      "3                           2A CALLE 4-40 ZONA 1      None   \n",
      "4                       10MA AVENIDA 5-38 ZONA 1      None   \n",
      "...                                          ...       ...   \n",
      "6585                             CANTÓN TZANJUYÚ  77217261   \n",
      "6586                            CANTÓN PACHICHAJ  77217550   \n",
      "6587                        COMUNIDAD DE CHUKMUK  58165683   \n",
      "6588  CANTON TZANCHALI, DE LA ALDEA CERRO DE ORO  43356322   \n",
      "6589                        COMUNIDAD DE CHUKMUK  58165683   \n",
      "\n",
      "                          SUPERVISOR                       DIRECTOR  \\\n",
      "0     CESAR ADALBERTO NOGUERA JACOME     HÉCTOR ALIDIO CERON BRENES   \n",
      "1     CESAR ADALBERTO NOGUERA JACOME            ROMEO RIVERA CHACÓN   \n",
      "2     CESAR ADALBERTO NOGUERA JACOME       JOSÉ VICENTE REYES SOLÍS   \n",
      "3     SILVIA MARILENA BUEZO MARTINEZ  ERWIN LEONEL COLINDRES MONROY   \n",
      "4     SILVIA MARILENA BUEZO MARTINEZ   ROXANA LISBETH URRUTIA PINTO   \n",
      "...                              ...                            ...   \n",
      "6585               JUAN POP CHAVAJAY             PEDRO SOSOF QUIEJÚ   \n",
      "6586               JUAN POP CHAVAJAY            GASPAR REANDA PABLO   \n",
      "6587               JUAN POP CHAVAJAY          JOSÉ MIGUEL POP TZINÁ   \n",
      "6588          NATANAEL MORALES PACAY     DAVID ABRAHAM COTZAL BARÁN   \n",
      "6589               JUAN POP CHAVAJAY          JOSÉ MIGUEL POP TZINÁ   \n",
      "\n",
      "              NIVEL  ... plan_SEMIPRESENCIAL es_publico es_rural  \\\n",
      "0     DIVERSIFICADO  ...               False          1        0   \n",
      "1     DIVERSIFICADO  ...               False          1        0   \n",
      "2     DIVERSIFICADO  ...               False          1        0   \n",
      "3     DIVERSIFICADO  ...               False          0        0   \n",
      "4     DIVERSIFICADO  ...               False          0        0   \n",
      "...             ...  ...                 ...        ...      ...   \n",
      "6585  DIVERSIFICADO  ...               False          0        0   \n",
      "6586  DIVERSIFICADO  ...               False          0        0   \n",
      "6587  DIVERSIFICADO  ...               False          1        1   \n",
      "6588  DIVERSIFICADO  ...               False          1        1   \n",
      "6589  DIVERSIFICADO  ...               False          1        1   \n",
      "\n",
      "     tiene_telefono plan_VIRTUAL A DISTANCIA plan_MIXTO area_SIN ESPECIFICAR  \\\n",
      "0                 0                      NaN        NaN                  NaN   \n",
      "1                 0                      NaN        NaN                  NaN   \n",
      "2                 0                      NaN        NaN                  NaN   \n",
      "3                 0                      NaN        NaN                  NaN   \n",
      "4                 0                      NaN        NaN                  NaN   \n",
      "...             ...                      ...        ...                  ...   \n",
      "6585              1                    False        NaN                  NaN   \n",
      "6586              1                    False        NaN                  NaN   \n",
      "6587              1                    False        NaN                  NaN   \n",
      "6588              1                    False        NaN                  NaN   \n",
      "6589              1                    False        NaN                  NaN   \n",
      "\n",
      "      plan_SABATINO plan_INTERCALADO  plan_DOMINICAL  \n",
      "0               NaN              NaN             NaN  \n",
      "1               NaN              NaN             NaN  \n",
      "2               NaN              NaN             NaN  \n",
      "3               NaN              NaN             NaN  \n",
      "4               NaN              NaN             NaN  \n",
      "...             ...              ...             ...  \n",
      "6585            NaN              NaN             NaN  \n",
      "6586            NaN              NaN             NaN  \n",
      "6587            NaN              NaN             NaN  \n",
      "6588            NaN              NaN             NaN  \n",
      "6589            NaN              NaN             NaN  \n",
      "\n",
      "[6590 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dd1db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 datasets procesados\n",
      "Columnas originales: 17\n",
      "Columnas finales: 41\n",
      "Nuevas columnas creadas: 24\n",
      "RESUMEN COMPLETO DEL DATASET LIMPIO (CON COLUMNAS EXTRAS):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing (%)</th>\n",
       "      <th>unique_values</th>\n",
       "      <th>sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TELEFONO</td>\n",
       "      <td>25.39</td>\n",
       "      <td>3186</td>\n",
       "      <td>[78328708, 78320670, 78320556, 78323391, 58437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CODIGO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6590</td>\n",
       "      <td>[20-01-0024-46, 20-01-0029-46, 20-01-0030-46, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISTRITO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>620</td>\n",
       "      <td>[20-001, 20-024, 20-027, 99-001, 20-030]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUNICIPIO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>343</td>\n",
       "      <td>[CHIQUIMULA, SAN JOSE LA ARADA, SAN JUAN ERMIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEPARTAMENTO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23</td>\n",
       "      <td>[CHIQUIMULA, SACATEPEQUEZ, ALTA VERAPAZ, SAN M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTABLECIMIENTO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3569</td>\n",
       "      <td>[ESCUELA DE CIENCIAS COMERCIALES NOCTURNA, INS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIRECCION</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4428</td>\n",
       "      <td>[10A. AVENIDA 3-71 ZONA 1, 2A CALLE ENTRE 11 Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>0.00</td>\n",
       "      <td>598</td>\n",
       "      <td>[CESAR ADALBERTO NOGUERA JACOME, SILVIA MARILE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3860</td>\n",
       "      <td>[HÉCTOR ALIDIO CERON BRENES, ROMEO RIVERA CHAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NIVEL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[DIVERSIFICADO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SECTOR</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>[OFICIAL, PRIVADO, COOPERATIVA, MUNICIPAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AREA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>[URBANA, RURAL, SIN ESPECIFICAR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>STATUS</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[ABIERTA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MODALIDAD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[MONOLINGUE, BILINGUE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JORNADA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>[NOCTURNA, VESPERTINA, DOBLE, MATUTINA, SIN JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PLAN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>[DIARIO, FIN DE SEMANA, A DISTANCIA, SEMIPRESE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEPARTAMENTAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>[CHIQUIMULA, SACATEPÉQUEZ, ALTA VERAPAZ, SAN M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sector_COOPERATIVA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sector_MUNICIPAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sector_OFICIAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sector_PRIVADO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>area_RURAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>area_URBANA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>modalidad_BILINGUE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>modalidad_MONOLINGUE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jornada_DOBLE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jornada_INTERMEDIA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>jornada_MATUTINA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jornada_NOCTURNA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jornada_SIN JORNADA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>jornada_VESPERTINA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>plan_A DISTANCIA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>plan_DIARIO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>plan_FIN DE SEMANA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>plan_SEMIPRESENCIAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>es_publico</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>es_rural</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>es_urbano</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tiene_telefono</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tipo_establecimiento</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>[ESCUELA_LICEO, INSTITUTO_COLEGIO, CENTRO, OTRO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>longitud_nombre</td>\n",
       "      <td>0.00</td>\n",
       "      <td>107</td>\n",
       "      <td>[40, 62, 81, 51, 31]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  column  missing (%)  unique_values  \\\n",
       "6               TELEFONO        25.39           3186   \n",
       "0                 CODIGO         0.00           6590   \n",
       "1               DISTRITO         0.00            620   \n",
       "3              MUNICIPIO         0.00            343   \n",
       "2           DEPARTAMENTO         0.00             23   \n",
       "4        ESTABLECIMIENTO         0.00           3569   \n",
       "5              DIRECCION         0.00           4428   \n",
       "7             SUPERVISOR         0.00            598   \n",
       "8               DIRECTOR         0.00           3860   \n",
       "9                  NIVEL         0.00              1   \n",
       "10                SECTOR         0.00              4   \n",
       "11                  AREA         0.00              3   \n",
       "12                STATUS         0.00              1   \n",
       "13             MODALIDAD         0.00              2   \n",
       "14               JORNADA         0.00              6   \n",
       "15                  PLAN         0.00              9   \n",
       "16         DEPARTAMENTAL         0.00             26   \n",
       "17    sector_COOPERATIVA         0.00              2   \n",
       "18      sector_MUNICIPAL         0.00              2   \n",
       "19        sector_OFICIAL         0.00              2   \n",
       "20        sector_PRIVADO         0.00              2   \n",
       "21            area_RURAL         0.00              2   \n",
       "22           area_URBANA         0.00              2   \n",
       "23    modalidad_BILINGUE         0.00              2   \n",
       "24  modalidad_MONOLINGUE         0.00              2   \n",
       "25         jornada_DOBLE         0.00              2   \n",
       "26    jornada_INTERMEDIA         0.00              2   \n",
       "27      jornada_MATUTINA         0.00              2   \n",
       "28      jornada_NOCTURNA         0.00              2   \n",
       "29   jornada_SIN JORNADA         0.00              2   \n",
       "30    jornada_VESPERTINA         0.00              2   \n",
       "31      plan_A DISTANCIA         0.00              2   \n",
       "32           plan_DIARIO         0.00              2   \n",
       "33    plan_FIN DE SEMANA         0.00              2   \n",
       "34   plan_SEMIPRESENCIAL         0.00              2   \n",
       "35            es_publico         0.00              2   \n",
       "36              es_rural         0.00              2   \n",
       "37             es_urbano         0.00              2   \n",
       "38        tiene_telefono         0.00              2   \n",
       "39  tipo_establecimiento         0.00              4   \n",
       "40       longitud_nombre         0.00            107   \n",
       "\n",
       "                                        sample_values  \n",
       "6   [78328708, 78320670, 78320556, 78323391, 58437...  \n",
       "0   [20-01-0024-46, 20-01-0029-46, 20-01-0030-46, ...  \n",
       "1            [20-001, 20-024, 20-027, 99-001, 20-030]  \n",
       "3   [CHIQUIMULA, SAN JOSE LA ARADA, SAN JUAN ERMIT...  \n",
       "2   [CHIQUIMULA, SACATEPEQUEZ, ALTA VERAPAZ, SAN M...  \n",
       "4   [ESCUELA DE CIENCIAS COMERCIALES NOCTURNA, INS...  \n",
       "5   [10A. AVENIDA 3-71 ZONA 1, 2A CALLE ENTRE 11 Y...  \n",
       "7   [CESAR ADALBERTO NOGUERA JACOME, SILVIA MARILE...  \n",
       "8   [HÉCTOR ALIDIO CERON BRENES, ROMEO RIVERA CHAC...  \n",
       "9                                     [DIVERSIFICADO]  \n",
       "10         [OFICIAL, PRIVADO, COOPERATIVA, MUNICIPAL]  \n",
       "11                   [URBANA, RURAL, SIN ESPECIFICAR]  \n",
       "12                                          [ABIERTA]  \n",
       "13                             [MONOLINGUE, BILINGUE]  \n",
       "14  [NOCTURNA, VESPERTINA, DOBLE, MATUTINA, SIN JO...  \n",
       "15  [DIARIO, FIN DE SEMANA, A DISTANCIA, SEMIPRESE...  \n",
       "16  [CHIQUIMULA, SACATEPÉQUEZ, ALTA VERAPAZ, SAN M...  \n",
       "17                                      [False, True]  \n",
       "18                                      [False, True]  \n",
       "19                                      [True, False]  \n",
       "20                                      [False, True]  \n",
       "21                                      [False, True]  \n",
       "22                                      [True, False]  \n",
       "23                                      [False, True]  \n",
       "24                                      [True, False]  \n",
       "25                                      [False, True]  \n",
       "26                                      [False, True]  \n",
       "27                                      [False, True]  \n",
       "28                                      [True, False]  \n",
       "29                                      [False, True]  \n",
       "30                                      [False, True]  \n",
       "31                                      [False, True]  \n",
       "32                                      [True, False]  \n",
       "33                                      [False, True]  \n",
       "34                                      [False, True]  \n",
       "35                                             [1, 0]  \n",
       "36                                             [0, 1]  \n",
       "37                                             [1, 0]  \n",
       "38                                             [0, 1]  \n",
       "39   [ESCUELA_LICEO, INSTITUTO_COLEGIO, CENTRO, OTRO]  \n",
       "40                               [40, 62, 81, 51, 31]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMPACTO DE LA LIMPIEZA:\n",
      "Total de registros: 6,590\n",
      "Teléfonos válidos: 4,917 (74.6%)\n",
      "Establecimientos sin comillas: 6,590\n",
      "Valores únicos en PLAN: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cleaned_datasets = {}\n",
    "for name, df in datasets.items():\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean['ESTABLECIMIENTO'] = df_clean['ESTABLECIMIENTO'].str.replace('\"', '', regex=False)\n",
    "    \n",
    "    df_clean['PLAN'] = df_clean['PLAN'].str.replace(r'\\s*\\([^)]*\\)', '', regex=True).str.strip()\n",
    "    \n",
    "    def clean_phone(phone):\n",
    "        if pd.isna(phone):\n",
    "            return None\n",
    "        phone_str = str(phone)\n",
    "        if '-' in phone_str:\n",
    "            phone_str = phone_str.split('-')[0]\n",
    "        numbers = re.sub(r'[^0-9]', '', phone_str)\n",
    "        if len(numbers) == 8:\n",
    "            return numbers\n",
    "        elif len(numbers) == 7 and numbers[0] in ['3', '4', '5']:\n",
    "            return '0' + numbers\n",
    "        elif len(numbers) == 7:\n",
    "            return numbers\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    df_clean['TELEFONO'] = df_clean['TELEFONO'].apply(clean_phone)\n",
    "    \n",
    "    categorical_fields = ['SECTOR', 'AREA', 'MODALIDAD', 'JORNADA', 'PLAN']\n",
    "    \n",
    "    for field in categorical_fields:\n",
    "        if field in df_clean.columns:\n",
    "            dummies = pd.get_dummies(df_clean[field], prefix=field.lower())\n",
    "            df_clean = pd.concat([df_clean, dummies], axis=1)\n",
    "    \n",
    "    df_clean['es_publico'] = df_clean['SECTOR'].isin(['OFICIAL', 'MUNICIPAL']).astype(int)\n",
    "    df_clean['es_rural'] = (df_clean['AREA'] == 'RURAL').astype(int)\n",
    "    df_clean['es_urbano'] = (df_clean['AREA'] == 'URBANA').astype(int)\n",
    "    df_clean['tiene_telefono'] = df_clean['TELEFONO'].notna().astype(int)\n",
    "    \n",
    "    def categorize_establishment(name):\n",
    "        name_upper = str(name).upper()\n",
    "        if any(word in name_upper for word in ['INSTITUTO', 'COLEGIO']):\n",
    "            return 'INSTITUTO_COLEGIO'\n",
    "        elif any(word in name_upper for word in ['ESCUELA', 'LICEO']):\n",
    "            return 'ESCUELA_LICEO'\n",
    "        elif any(word in name_upper for word in ['CENTRO', 'NUCLEO']):\n",
    "            return 'CENTRO'\n",
    "        else:\n",
    "            return 'OTRO'\n",
    "    \n",
    "    df_clean['tipo_establecimiento'] = df_clean['ESTABLECIMIENTO'].apply(categorize_establishment)\n",
    "    df_clean['longitud_nombre'] = df_clean['ESTABLECIMIENTO'].str.len()\n",
    "    \n",
    "    cleaned_datasets[name] = df_clean\n",
    "\n",
    "sample_df = list(cleaned_datasets.values())[0]\n",
    "original_cols = 17  \n",
    "new_cols = len(sample_df.columns)\n",
    "print(f\"{len(cleaned_datasets)} datasets procesados\")\n",
    "print(f\"Columnas originales: {original_cols}\")\n",
    "print(f\"Columnas finales: {new_cols}\")\n",
    "print(f\"Nuevas columnas creadas: {new_cols - original_cols}\")\n",
    "\n",
    "all_columns = list(cleaned_datasets[list(cleaned_datasets.keys())[0]].columns)\n",
    "summary_stats = []\n",
    "\n",
    "for col in all_columns:\n",
    "    col_data = []\n",
    "    for name, df in cleaned_datasets.items():\n",
    "        if col in df.columns:\n",
    "            series = df[col].astype(str).str.strip()\n",
    "            col_data.extend(series)\n",
    "\n",
    "    series_all = pd.Series(col_data)\n",
    "    n_total = len(series_all)\n",
    "    n_missing = (series_all == \"\").sum() + series_all.isna().sum() + (series_all == \"None\").sum()\n",
    "    n_unique = series_all.nunique()\n",
    "    \n",
    "    valid_values = series_all[(series_all != \"\") & (series_all.notna()) & (series_all != \"None\")]\n",
    "    sample_values = valid_values.unique()[:5].tolist() if len(valid_values) > 0 else []\n",
    "    \n",
    "    summary_stats.append({\n",
    "        \"column\": col,\n",
    "        \"missing (%)\": round((n_missing / n_total) * 100, 2),\n",
    "        \"unique_values\": n_unique,\n",
    "        \"sample_values\": sample_values\n",
    "    })\n",
    "\n",
    "df_summary_clean = pd.DataFrame(summary_stats)\n",
    "df_summary_clean.sort_values(\"missing (%)\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"RESUMEN COMPLETO DEL DATASET LIMPIO (CON COLUMNAS EXTRAS):\")\n",
    "display(df_summary_clean)\n",
    "\n",
    "print(f\"\\nIMPACTO DE LA LIMPIEZA:\")\n",
    "total_records = sum(len(df) for df in cleaned_datasets.values())\n",
    "print(f\"Total de registros: {total_records:,}\")\n",
    "\n",
    "combined_clean = pd.concat(cleaned_datasets.values(), ignore_index=True)\n",
    "print(f\"Teléfonos válidos: {combined_clean['TELEFONO'].notna().sum():,} ({combined_clean['TELEFONO'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"Establecimientos sin comillas: {(~combined_clean['ESTABLECIMIENTO'].str.contains('\"', na=False)).sum():,}\")\n",
    "print(f\"Valores únicos en PLAN: {combined_clean['PLAN'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
