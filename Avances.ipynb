{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1fe888",
   "metadata": {},
   "source": [
    "# Carga de Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68500dc5",
   "metadata": {},
   "source": [
    "## .xls / HTML a .csv\n",
    "Los datos del Mineduc se exportan como archivos .xls, realmente teniendo contenido de HTML. Debido a eso, debemos de parsear el archivo HTML e identificar la tabla correcta que contiene los datos. Luego, podemos exportar los datos a su archivo .csv correspondiente, utilizando el valor de la columna 'Departamento' para nombrarlo. Adicionalmente, los archivos utilizan un encoding diferente al est√°ndar utf-8, por lo cual vamos a especificarlo al momento de leer los archivos HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a36f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single file test successful!\n",
      "\n",
      "============================================================\n",
      "PROCESSING ALL FILES\n",
      "============================================================\n",
      "Found 23 .xls files to process\n",
      "  ‚úÖ Processed establecimiento (7).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (6).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (5).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (1).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (19).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (3).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (4).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (15).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (10).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (22).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (2).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento.xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (21).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (17).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (9).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (13).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (12).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (18).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (16).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (20).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (8).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (14).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (11).xls: Created 1 CSVs.\n",
      "\n",
      "============================================================\n",
      "PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total files: 23\n",
      "‚úÖ Successful: 23\n",
      "‚ùå Failed: 0\n",
      "\n",
      "‚úÖ No duplicate departamentos found\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_html_excel_file(file_path):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    try:\n",
    "        tables = pd.read_html(str(file_path), encoding=\"iso-8859-1\")\n",
    "\n",
    "        if not tables:\n",
    "            return {\"success\": False, \"error\": \"No tables found in HTML\"}\n",
    "\n",
    "        required_headers = [\"CODIGO\", \"DISTRITO\", \"DEPARTAMENTO\", \"MUNICIPIO\"]\n",
    "        target_table = None\n",
    "        target_index = None\n",
    "\n",
    "        for i, df in enumerate(tables):\n",
    "            df_columns_upper = [str(col).upper().strip() for col in df.columns]\n",
    "            if all(header in df_columns_upper for header in required_headers):\n",
    "                target_table = df\n",
    "                target_index = i\n",
    "                break\n",
    "            else:\n",
    "                if len(df) > 0:\n",
    "                    first_row_upper = [\n",
    "                        str(cell).upper().strip() for cell in df.iloc[0]\n",
    "                    ]\n",
    "                    if all(header in first_row_upper for header in required_headers):\n",
    "                        df.columns = df.iloc[0]\n",
    "                        df = df.drop(df.index[0]).reset_index(drop=True)\n",
    "                        target_table = df\n",
    "                        target_index = i\n",
    "                        break\n",
    "\n",
    "        if target_table is None:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"No table found with required headers.\",\n",
    "            }\n",
    "\n",
    "        target_table = target_table.dropna(how=\"all\")\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": target_table,\n",
    "            \"table_index\": target_index,\n",
    "            \"total_tables\": len(tables),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def sanitize_filename(text):\n",
    "    filename = text.lower().replace(\" \", \"_\")\n",
    "    return re.sub(r\"[^\\w_.]\", \"\", filename)\n",
    "\n",
    "\n",
    "def process_html_files_directory(input_dir, output_dir):\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = list(input_path.glob(\"*.xls\"))\n",
    "\n",
    "    print(f\"Found {len(files)} .xls files to process\")\n",
    "\n",
    "    successful_files = []\n",
    "    failed_files = []\n",
    "    all_departamentos = defaultdict(list)\n",
    "\n",
    "    for file_path in files:\n",
    "        result = parse_html_excel_file(file_path)\n",
    "\n",
    "        if result[\"success\"]:\n",
    "            df = result[\"data\"]\n",
    "\n",
    "            departamentos = []\n",
    "            for departamento, group in df.groupby(\"DEPARTAMENTO\"):\n",
    "                filename = f\"datos_{sanitize_filename(departamento)}.csv\"\n",
    "\n",
    "                output_file = output_path / filename\n",
    "                group.to_csv(output_file, index=False)\n",
    "\n",
    "                departamentos.append(\n",
    "                    {\"name\": departamento, \"filename\": filename, \"rows\": len(group)}\n",
    "                )\n",
    "\n",
    "                all_departamentos[departamento].append(\n",
    "                    {\n",
    "                        \"source_file\": file_path.name,\n",
    "                        \"csv_file\": filename,\n",
    "                        \"rows\": len(group),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            successful_files.append(\n",
    "                {\n",
    "                    \"file\": file_path.name,\n",
    "                    \"departamentos\": departamentos,\n",
    "                    \"total_rows\": len(df),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(f\"  ‚úÖ Processed {file_path.name}: Created {len(departamentos)} CSVs.\")\n",
    "\n",
    "        else:\n",
    "            failed_files.append({\"file\": file_path.name, \"error\": result[\"error\"]})\n",
    "            print(f\"  ‚ùå Failed {file_path.name}: {result['error']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\nTotal files: {len(files)}\")\n",
    "    print(f\"‚úÖ Successful: {len(successful_files)}\")\n",
    "    print(f\"‚ùå Failed: {len(failed_files)}\")\n",
    "\n",
    "    # The detailed successful/failed files lists will only be printed if there are successful/failed files.\n",
    "    # The summary already gives a count, so the repetition for successful files is removed here.\n",
    "    # The detailed list for failed files remains as it provides useful error messages.\n",
    "    if failed_files:\n",
    "        print(f\"\\n‚ùå FAILED FILES:\")\n",
    "        for item in failed_files:\n",
    "            print(f\"  - {item['file']}: {item['error']}\")\n",
    "\n",
    "    duplicates = {\n",
    "        name: sources\n",
    "        for name, sources in all_departamentos.items()\n",
    "        if len(sources) > 1\n",
    "    }\n",
    "    if duplicates:\n",
    "        print(f\"\\n‚ö†Ô∏è DUPLICATE DEPARTAMENTOS:\")\n",
    "        for dept_name, sources in duplicates.items():\n",
    "            print(f\"  {dept_name}: appears in {len(sources)} files\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No duplicate departamentos found\")\n",
    "\n",
    "\n",
    "test_result = parse_html_excel_file(\"data/raw/establecimiento.xls\")\n",
    "if test_result[\"success\"]:\n",
    "    print(\"\\nSingle file test successful!\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING ALL FILES\")\n",
    "    print(\"=\" * 60)\n",
    "    process_html_files_directory(\"data/raw\", \"data/csv\")\n",
    "else:\n",
    "    print(f\"‚ùå Single file test failed: {test_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e96a1",
   "metadata": {},
   "source": [
    "## .csv a DataFrames\n",
    "Luego de haber creado los archivos, podemos cargarlos a DataFrames para realizar el an√°lisis necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89bd3c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 CSV files\n",
      "Loaded 23 datasets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load all CSV files\n",
    "csv_dir = Path(\"data/csv\")\n",
    "csv_files = list(csv_dir.glob(\"*.csv\"))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "# Load all datasets\n",
    "datasets = {}\n",
    "for csv_file in csv_files:\n",
    "    dataset_name = csv_file.stem\n",
    "    datasets[dataset_name] = pd.read_csv(csv_file)\n",
    "    \n",
    "print(f\"Loaded {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9176a2",
   "metadata": {},
   "source": [
    "# Descripci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad22cb",
   "metadata": {},
   "source": [
    "## Filas y Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09701424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Shapes:\n",
      "                 dataset  rows  columns\n",
      "0        datos_guatemala  1036       17\n",
      "12  datos_ciudad_capital   864       17\n",
      "16      datos_san_marcos   431       17\n",
      "17       datos_escuintla   393       17\n",
      "5   datos_quetzaltenango   365       17\n",
      "7    datos_chimaltenango   300       17\n",
      "11   datos_suchitepequez   296       17\n",
      "14         datos_jutiapa   296       17\n",
      "3    datos_huehuetenango   295       17\n",
      "9     datos_alta_verapaz   294       17\n",
      "18          datos_izabal   273       17\n",
      "22      datos_retalhuleu   272       17\n",
      "19           datos_peten   270       17\n",
      "21    datos_sacatepequez   208       17\n",
      "4           datos_quiche   184       17\n",
      "2       datos_chiquimula   136       17\n",
      "10      datos_santa_rosa   133       17\n",
      "15          datos_jalapa   121       17\n",
      "20          datos_solola   111       17\n",
      "8      datos_el_progreso    97       17\n",
      "1     datos_baja_verapaz    94       17\n",
      "6           datos_zacapa    70       17\n",
      "13     datos_totonicapan    51       17\n",
      "\n",
      "üìà Summary:\n",
      "Total rows across all datasets: 6,590\n",
      "Average rows per dataset: 287\n",
      "Min/Max rows: 51 / 1036\n"
     ]
    }
   ],
   "source": [
    "shape_info = []\n",
    "for name, df in datasets.items():\n",
    "    shape_info.append({\n",
    "        'dataset': name,\n",
    "        'rows': df.shape[0],\n",
    "        'columns': df.shape[1]\n",
    "    })\n",
    "\n",
    "shape_df = pd.DataFrame(shape_info)\n",
    "print(\"üìä Dataset Shapes:\")\n",
    "print(shape_df.sort_values('rows', ascending=False))\n",
    "\n",
    "print(f\"\\nüìà Summary:\")\n",
    "print(f\"Total rows across all datasets: {shape_df['rows'].sum():,}\")\n",
    "print(f\"Average rows per dataset: {shape_df['rows'].mean():.0f}\")\n",
    "print(f\"Min/Max rows: {shape_df['rows'].min()} / {shape_df['rows'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd8fd4",
   "metadata": {},
   "source": [
    "## Integridad de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5fef65",
   "metadata": {},
   "source": [
    "### Consistencia en Nombres de Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e31a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Standard columns (17):\n",
      "   1. CODIGO\n",
      "   2. DISTRITO\n",
      "   3. DEPARTAMENTO\n",
      "   4. MUNICIPIO\n",
      "   5. ESTABLECIMIENTO\n",
      "   6. DIRECCION\n",
      "   7. TELEFONO\n",
      "   8. SUPERVISOR\n",
      "   9. DIRECTOR\n",
      "  10. NIVEL\n",
      "  11. SECTOR\n",
      "  12. AREA\n",
      "  13. STATUS\n",
      "  14. MODALIDAD\n",
      "  15. JORNADA\n",
      "  16. PLAN\n",
      "  17. DEPARTAMENTAL\n"
     ]
    }
   ],
   "source": [
    "all_columns = []\n",
    "column_consistency = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    columns = list(df.columns)\n",
    "    all_columns.append(columns)\n",
    "    column_consistency[name] = columns\n",
    "\n",
    "first_columns = all_columns[0]\n",
    "all_same = all(columns == first_columns for columns in all_columns)\n",
    "\n",
    "if all_same:\n",
    "    print(f\"\\n‚úÖ Standard columns ({len(first_columns)}):\")\n",
    "    for i, col in enumerate(first_columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Column differences found:\")\n",
    "    for name, columns in column_consistency.items():\n",
    "        if columns != first_columns:\n",
    "            print(f\"  {name}: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54d5d4",
   "metadata": {},
   "source": [
    "### Encoding Problem√°tico\n",
    "Como mencionamos anteriormente, el encoding de los archivos originales era distinto de \"utf-8\". Nos dimos cuenta al realizar el an√°lisis sobre el encoding problem√°tico, sin embargo al cambiarlo dentro de la funci√≥n anterior logramos correr con √©xito este an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330170f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No encoding issues found (char: 'ÔøΩ')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "problematic_char = \"ÔøΩ\"\n",
    "all_problematic_samples = defaultdict(list)\n",
    "issue_found = False\n",
    "\n",
    "for dataset_name, df in datasets.items():\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            str_series = df[col].astype(str) \n",
    "            \n",
    "            contains_char_mask = str_series.str.contains(problematic_char, na=False)\n",
    "            \n",
    "            if contains_char_mask.any():\n",
    "                issue_found = True\n",
    "                current_samples = str_series[contains_char_mask].unique().tolist()\n",
    "                for sample_val in current_samples:\n",
    "                    if len(all_problematic_samples[col]) < 5:\n",
    "                        all_problematic_samples[col].append(sample_val)\n",
    "\n",
    "\n",
    "if issue_found:\n",
    "    print(f\"‚ùå Encoding issues found (char: '{problematic_char}'):\")\n",
    "    sorted_cols_with_issues = sorted(all_problematic_samples.keys()) \n",
    "\n",
    "    for col in sorted_cols_with_issues:\n",
    "        samples = all_problematic_samples[col]\n",
    "        print(f\"  Column '{col}':\")\n",
    "        for val in samples:\n",
    "            print(f\"    ‚Ä¢ {val}\")\n",
    "else:\n",
    "    print(f\"‚úÖ No encoding issues found (char: '{problematic_char}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d679f59",
   "metadata": {},
   "source": [
    "# An√°lisis de Variables\n",
    "Las variables que m√°s operaciones de limpieza necesitan son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1129942-f7f7-4b02-898b-85e15159e4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing (%)</th>\n",
       "      <th>unique_values</th>\n",
       "      <th>sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CODIGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590</td>\n",
       "      <td>[01-02-0012-46, 01-02-0013-46, 01-02-0022-46, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISTRITO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620</td>\n",
       "      <td>[01-502, 01-405, 01-510, 01-644, 01-645]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEPARTAMENTO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>[GUATEMALA, BAJA VERAPAZ, CHIQUIMULA, HUEHUETE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUNICIPIO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>343</td>\n",
       "      <td>[SANTA CATARINA PINULA, SAN JOSE PINULA, SAN J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTABLECIMIENTO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3779</td>\n",
       "      <td>[LICEO INTEGRAL DE ENSE√ëANZA COMERCIAL, INSTIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIRECCION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4428</td>\n",
       "      <td>[SECTOR LOS TRES REYES, LOTE 5\"E\" ZONA 7 ALDEA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TELEFONO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4208</td>\n",
       "      <td>[58543592, 66373741, 23660520, 66371400, 66339...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>598</td>\n",
       "      <td>[JULIA ENECON ROCA MORAN, BLANCA SARAI GUTIERR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3860</td>\n",
       "      <td>[JOS√â ADOLFO ESPINOZA MORATAYA, EDGAR EFRA√çN R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NIVEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[DIVERSIFICADO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SECTOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[PRIVADO, OFICIAL, COOPERATIVA, MUNICIPAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AREA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[URBANA, RURAL, SIN ESPECIFICAR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>STATUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ABIERTA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MODALIDAD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[MONOLINGUE, BILINGUE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JORNADA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>[MATUTINA, DOBLE, VESPERTINA, SIN JORNADA, NOC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PLAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>[DIARIO(REGULAR), FIN DE SEMANA, SEMIPRESENCIA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEPARTAMENTAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[GUATEMALA ORIENTE, GUATEMALA NORTE, GUATEMALA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column  missing (%)  unique_values  \\\n",
       "0            CODIGO          0.0           6590   \n",
       "1          DISTRITO          0.0            620   \n",
       "2      DEPARTAMENTO          0.0             23   \n",
       "3         MUNICIPIO          0.0            343   \n",
       "4   ESTABLECIMIENTO          0.0           3779   \n",
       "5         DIRECCION          0.0           4428   \n",
       "6          TELEFONO          0.0           4208   \n",
       "7        SUPERVISOR          0.0            598   \n",
       "8          DIRECTOR          0.0           3860   \n",
       "9             NIVEL          0.0              1   \n",
       "10           SECTOR          0.0              4   \n",
       "11             AREA          0.0              3   \n",
       "12           STATUS          0.0              1   \n",
       "13        MODALIDAD          0.0              2   \n",
       "14          JORNADA          0.0              6   \n",
       "15             PLAN          0.0             12   \n",
       "16    DEPARTAMENTAL          0.0             26   \n",
       "\n",
       "                                        sample_values  \n",
       "0   [01-02-0012-46, 01-02-0013-46, 01-02-0022-46, ...  \n",
       "1            [01-502, 01-405, 01-510, 01-644, 01-645]  \n",
       "2   [GUATEMALA, BAJA VERAPAZ, CHIQUIMULA, HUEHUETE...  \n",
       "3   [SANTA CATARINA PINULA, SAN JOSE PINULA, SAN J...  \n",
       "4   [LICEO INTEGRAL DE ENSE√ëANZA COMERCIAL, INSTIT...  \n",
       "5   [SECTOR LOS TRES REYES, LOTE 5\"E\" ZONA 7 ALDEA...  \n",
       "6   [58543592, 66373741, 23660520, 66371400, 66339...  \n",
       "7   [JULIA ENECON ROCA MORAN, BLANCA SARAI GUTIERR...  \n",
       "8   [JOS√â ADOLFO ESPINOZA MORATAYA, EDGAR EFRA√çN R...  \n",
       "9                                     [DIVERSIFICADO]  \n",
       "10         [PRIVADO, OFICIAL, COOPERATIVA, MUNICIPAL]  \n",
       "11                   [URBANA, RURAL, SIN ESPECIFICAR]  \n",
       "12                                          [ABIERTA]  \n",
       "13                             [MONOLINGUE, BILINGUE]  \n",
       "14  [MATUTINA, DOBLE, VESPERTINA, SIN JORNADA, NOC...  \n",
       "15  [DIARIO(REGULAR), FIN DE SEMANA, SEMIPRESENCIA...  \n",
       "16  [GUATEMALA ORIENTE, GUATEMALA NORTE, GUATEMALA...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_stats = []\n",
    "\n",
    "for col in first_columns:\n",
    "    col_data = []\n",
    "    for name, df in datasets.items():\n",
    "        if col in df.columns:\n",
    "            series = df[col].astype(str).str.strip()\n",
    "            col_data.extend(series)\n",
    "\n",
    "    series_all = pd.Series(col_data)\n",
    "    n_total = len(series_all)\n",
    "    n_missing = (series_all == \"\").sum() + series_all.isna().sum()\n",
    "    n_unique = series_all.nunique()\n",
    "    \n",
    "    summary_stats.append({\n",
    "        \"column\": col,\n",
    "        \"missing (%)\": round((n_missing / n_total) * 100, 2),\n",
    "        \"unique_values\": n_unique,\n",
    "        \"sample_values\": series_all.dropna().unique()[:5].tolist()\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_stats)\n",
    "df_summary.sort_values(\"missing (%)\", ascending=False, inplace=True)\n",
    "\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8735b0",
   "metadata": {},
   "source": [
    "## C√≥digo\n",
    "Este valor parece ser un identificador √∫nico, queremos explorar las siguientes propiedades:\n",
    "- Unicidad: Este c√≥digo es √∫nico dentro de su respectivo dataset o todos?\n",
    "- Formato: Es consistente el formato en todos los datasets? Existen errores de digitaci√≥n?\n",
    "- Valores Faltantes: Existen valores faltantes?\n",
    "- Nos ayuda a identificar √∫nicamente alg√∫n otro valor?\n",
    "\n",
    "Debido a esto, queremos realizar los siguientes pasos de limpieza:\n",
    "\n",
    "- Identificar unicidad del c√≥digo\n",
    "- Identificar Valores Faltantes\n",
    "- Revisar errores de digitaci√≥n, c√≥mo lo pueden ser whitespaces o formato incongruente\n",
    "- Identificar si nos puede ayudar a identificar otras variables para verificar errores de digitaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a4fee8",
   "metadata": {},
   "source": [
    "## Distrito\n",
    "Este valor parece ser un identificador geogr√°fico, siguiendo un formato XX-YYY. Queremos explorar las siguientes propiedades\n",
    "- Formato: Es consistente el formato?\n",
    "- Valores Faltantes: Existen valores faltantes dentro de los datasets?\n",
    "- Nos ayuda a identificar √∫nicamente alg√∫n otro valor?\n",
    "\n",
    "Debido a esto, queremos realizar los siguientes pasos de limpieza:\n",
    "\n",
    "- Identificar valores faltantes\n",
    "- Revisar errores de digitaci√≥n\n",
    "- Enforzar un formato consistente\n",
    "- Identificar si nos puede ayuda a verificar la consistencia de Municipio o alg√∫n otro valor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5415d62",
   "metadata": {},
   "source": [
    "## Departamento\n",
    "\n",
    "Ya que los DataFrames se encuentran divididos por departamento, esta entrada deber√≠a ser completamente consistente. Adem√°s, podemos proponer los siguientes pasos para una mayor consistencia:\n",
    "\n",
    "- Identificar el valor RAW m√°s com√∫n, ya que un error de digitaci√≥n ser√≠a menos frecuente\n",
    "- Tomar ese valor y realizar las siguientes transformaciones\n",
    "    - Conversi√≥n a min√∫sculas\n",
    "    - Reemplazo de espacios por _\n",
    "    - Aplicar a todas las columnas de cada DF individual\n",
    "- Aplicar OHE luego de mergear los DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e2a71",
   "metadata": {},
   "source": [
    "## Municipio\n",
    "\n",
    "Este valor representa la divisi√≥n pol√≠tica a nivel municipal. Dado que se usa como categor√≠a geogr√°fica clave, es esencial asegurar consistencia.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Formato: ¬øSe encuentra todo en may√∫sculas? ¬øHay tildes inconsistentes?\n",
    "- Valores Faltantes: Confirmar si hay celdas vac√≠as o marcadas incorrectamente.\n",
    "- Relaci√≥n con otros campos: ¬øEl municipio concuerda con el departamento correspondiente?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Convertir todo el texto a may√∫sculas (.str.upper()).\n",
    "- Eliminar espacios extra antes o despu√©s (.str.strip()).\n",
    "- Normalizar tildes y caracteres especiales si necesario.\n",
    "- Validar los municipios contra una lista oficial por departamento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddb656",
   "metadata": {},
   "source": [
    "## Establecimiento\n",
    "\n",
    "Nombre propio de la instituci√≥n educativa. Puede contener muchas variantes tipogr√°ficas y estil√≠sticas que dificultan an√°lisis posteriores.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Formato: ¬øSe mantiene una capitalizaci√≥n consistente?\n",
    "- Valores Faltantes: ¬øHay registros sin nombre?\n",
    "- Redundancia o duplicaci√≥n: ¬øExisten nombres duplicados con leves diferencias?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Capitalizar nombres con .str.title() para uniformidad visual.\n",
    "- Eliminar espacios repetidos entre palabras.\n",
    "- Remover puntuaci√≥n innecesaria.\n",
    "- Establecer reglas para abreviaciones comunes si se encuentran (ej. \"Inst.\" por \"Instituto\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0133d64-4ad1-4159-83eb-9c65b77ad67f",
   "metadata": {},
   "source": [
    "## DIRECCI√ìN\n",
    "\n",
    "Campo libre con alta variabilidad. Las direcciones pueden contener m√∫ltiples abreviaturas, puntuaci√≥n, y errores de digitaci√≥n.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "- Formato: ¬øExisten patrones comunes? ¬øSe usan abreviaturas (CALLE, AV, etc.)?\n",
    "- Valores inconsistentes: ¬øUso indistinto de may√∫sculas, puntuaci√≥n, acentos?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "- Normalizar a may√∫sculas (.str.upper()).\n",
    "- Crear reglas de sustituci√≥n para abreviaturas frecuentes (ej. AVENIDA ‚Üí AV.).\n",
    "- Quitar s√≠mbolos innecesarios y estandarizar signos de puntuaci√≥n.\n",
    "- Opcional: usar expresiones regulares para separar partes de la direcci√≥n (calle, n√∫mero, zona, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bff941-e337-4303-aa50-85cb514fc243",
   "metadata": {},
   "source": [
    "## TEL√âFONO\n",
    "\n",
    "Campo num√©rico con alta variabilidad en formato. Puede contener n√∫meros concatenados, separadores o caracteres no num√©ricos.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "- Formato: ¬øTodos los valores contienen exactamente 8 d√≠gitos? ¬øHay m√∫ltiples n√∫meros por celda?\n",
    "- Errores: ¬øCaracteres no num√©ricos? ¬øEspacios o signos innecesarios?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Remover todos los caracteres no num√©ricos con re.sub(r\"\\D\", \"\", telefono).\n",
    "- Validar longitud est√°ndar (8 d√≠gitos en Guatemala).\n",
    "- Si hay m√∫ltiples n√∫meros, dividir y elegir el primero o guardarlos como lista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968f088-68f0-45d5-8365-9ab8c5208b4d",
   "metadata": {},
   "source": [
    "## SUPERVISOR\n",
    "\n",
    "Nombre del supervisor responsable. Puede presentar variaciones por uso de tildes, may√∫sculas, y errores ortogr√°ficos menores.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Formato: ¬øMay√∫sculas/min√∫sculas inconsistentes?\n",
    "- Duplicaci√≥n: ¬øUn mismo nombre aparece escrito de m√∫ltiples formas?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Capitalizar con .str.title() para uniformidad.\n",
    "- Remover espacios dobles y caracteres extra√±os.\n",
    "- Normalizar tildes si es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67f16-f9a8-4fdc-9a0f-5e188d88a914",
   "metadata": {},
   "source": [
    "## DIRECTOR\n",
    "\n",
    "Similar al campo de supervisor, representa nombres propios con riesgos similares de inconsistencia.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Aplicar los mismos criterios que SUPERVISOR.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Igual estrategia de capitalizaci√≥n, limpieza de espacios, y normalizaci√≥n de caracteres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8203578-43ba-44f3-b112-e7e765512022",
   "metadata": {},
   "source": [
    "## NIVEL\n",
    "Este campo tiene un √∫nico valor: \"DIVERSIFICADO\".\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Verificar que efectivamente todos los valores son iguales.\n",
    "- Confirmar si es √∫til conservar esta columna.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Si es redundante, considerar eliminarla para evitar ruido en an√°lisis futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b7908-d5b2-4bcf-8dba-479bc1d64b9f",
   "metadata": {},
   "source": [
    "## SECTOR\n",
    "\n",
    "Categor√≠a con pocos valores √∫nicos. Se espera valores como \"OFICIAL\", \"PRIVADO\", etc.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- ¬øMay√∫sculas o min√∫sculas inconsistentes?\n",
    "- ¬øErrores ortogr√°ficos?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Convertir todo a may√∫sculas y eliminar espacios (.str.upper().str.strip()).\n",
    "- Validar los valores contra un conjunto permitido: {OFICIAL, PRIVADO, MUNICIPAL, COOPERATIVA}.\n",
    "- Convertir a tipo Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5b092-16d1-4790-be2e-4976d8533f41",
   "metadata": {},
   "source": [
    "## √ÅREA\n",
    "Identifica si la instituci√≥n est√° en zona rural o urbana.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Confirmar que los valores son: URBANA, RURAL, SIN ESPECIFICAR.\n",
    "- Verificar errores de digitaci√≥n o combinaciones no v√°lidas.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Uniformar may√∫sculas (.str.upper()).\n",
    "- Reemplazar variantes de ‚Äúsin especificar‚Äù por un valor est√°ndar (ej. \"DESCONOCIDO\").\n",
    "- Convertir a Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb68b7",
   "metadata": {},
   "source": [
    "## STATUS\n",
    "Campo con un √∫nico valor: \"ABIERTA\".\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "Verificar si realmente todos los valores son iguales.\n",
    "\n",
    "Evaluar su utilidad en an√°lisis futuros.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Eliminar si es redundante (sin variabilidad)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4aaf2",
   "metadata": {},
   "source": [
    "## MODALIDAD\n",
    "Pocos valores √∫nicos: \"MONOLINGUE\", \"BILINGUE\".\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "Verificar may√∫sculas y tildes.\n",
    "\n",
    "Validar que no existan variantes escritas incorrectamente.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Uniformar may√∫sculas y acentos (.str.upper()).\n",
    "\n",
    "Reemplazar variantes con un mapeo fijo.\n",
    "\n",
    "Convertir a Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c401d",
   "metadata": {},
   "source": [
    "## JORNADA\n",
    "Categor√≠a horaria. Existen valores como ‚ÄúMATUTINA‚Äù, ‚ÄúVESPERTINA‚Äù, ‚ÄúDOBLE‚Äù, ‚ÄúNOCHE‚Äù, etc.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "Verificar consistencia de t√©rminos.\n",
    "\n",
    "Identificar redundancias o t√©rminos similares con diferencias menores.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Normalizar formato (.str.upper().str.strip()).\n",
    "\n",
    "Mapear variantes a un conjunto est√°ndar.\n",
    "\n",
    "Eliminar signos extra o abreviaciones inconsistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070a90f",
   "metadata": {},
   "source": [
    "## PLAN\n",
    "Puede incluir valores con par√©ntesis, como ‚ÄúDIARIO(REGULAR)‚Äù, que dificultan an√°lisis.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "¬øHay signos innecesarios como par√©ntesis o guiones?\n",
    "\n",
    "¬øHay t√©rminos redundantes?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Eliminar par√©ntesis y su contenido con str.replace(r'\\(.*?\\)', '').\n",
    "\n",
    "Eliminar espacios extra y convertir a may√∫sculas.\n",
    "\n",
    "Validar valores contra una lista limpia predefinida.\n",
    "\n",
    "Convertir a Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b50ae",
   "metadata": {},
   "source": [
    "## DEPARTAMENTAL\n",
    "Representa una divisi√≥n regional administrativa.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "Verificar may√∫sculas, errores tipogr√°ficos.\n",
    "\n",
    "Confirmar que corresponde con el valor del campo DEPARTAMENTO.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Uniformar texto (.str.upper().str.strip()).\n",
    "\n",
    "Validar contra un listado oficial del MINEDUC.\n",
    "\n",
    "Opcional: cruzar con DEPARTAMENTO para consistencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
