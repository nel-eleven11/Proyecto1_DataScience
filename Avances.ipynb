{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1fe888",
   "metadata": {},
   "source": [
    "# Carga de Datos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68500dc5",
   "metadata": {},
   "source": [
    "## .xls / HTML a .csv\n",
    "Los datos del Mineduc se exportan como archivos .xls, realmente teniendo contenido de HTML. Debido a eso, debemos de parsear el archivo HTML e identificar la tabla correcta que contiene los datos. Luego, podemos exportar los datos a su archivo .csv correspondiente, utilizando el valor de la columna 'Departamento' para nombrarlo. Adicionalmente, los archivos utilizan un encoding diferente al est√°ndar utf-8, por lo cual vamos a especificarlo al momento de leer los archivos HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a36f5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Single file test successful!\n",
      "\n",
      "============================================================\n",
      "PROCESSING ALL FILES\n",
      "============================================================\n",
      "Found 23 .xls files to process\n",
      "  ‚úÖ Processed establecimiento (12).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (18).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (14).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (10).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (5).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento.xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (11).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (22).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (9).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (3).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (13).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (21).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (17).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (20).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (19).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (16).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (6).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (4).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (2).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (1).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (15).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (8).xls: Created 1 CSVs.\n",
      "  ‚úÖ Processed establecimiento (7).xls: Created 1 CSVs.\n",
      "\n",
      "============================================================\n",
      "PROCESSING SUMMARY\n",
      "============================================================\n",
      "\n",
      "Total files: 23\n",
      "‚úÖ Successful: 23\n",
      "‚ùå Failed: 0\n",
      "\n",
      "‚úÖ No duplicate departamentos found\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_html_excel_file(file_path):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    try:\n",
    "        tables = pd.read_html(str(file_path), encoding=\"iso-8859-1\")\n",
    "\n",
    "        if not tables:\n",
    "            return {\"success\": False, \"error\": \"No tables found in HTML\"}\n",
    "\n",
    "        required_headers = [\"CODIGO\", \"DISTRITO\", \"DEPARTAMENTO\", \"MUNICIPIO\"]\n",
    "        target_table = None\n",
    "        target_index = None\n",
    "\n",
    "        for i, df in enumerate(tables):\n",
    "            df_columns_upper = [str(col).upper().strip() for col in df.columns]\n",
    "            if all(header in df_columns_upper for header in required_headers):\n",
    "                target_table = df\n",
    "                target_index = i\n",
    "                break\n",
    "            else:\n",
    "                if len(df) > 0:\n",
    "                    first_row_upper = [\n",
    "                        str(cell).upper().strip() for cell in df.iloc[0]\n",
    "                    ]\n",
    "                    if all(header in first_row_upper for header in required_headers):\n",
    "                        df.columns = df.iloc[0]\n",
    "                        df = df.drop(df.index[0]).reset_index(drop=True)\n",
    "                        target_table = df\n",
    "                        target_index = i\n",
    "                        break\n",
    "\n",
    "        if target_table is None:\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"error\": \"No table found with required headers.\",\n",
    "            }\n",
    "\n",
    "        target_table = target_table.dropna(how=\"all\")\n",
    "\n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"data\": target_table,\n",
    "            \"table_index\": target_index,\n",
    "            \"total_tables\": len(tables),\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "\n",
    "def sanitize_filename(text):\n",
    "    filename = text.lower().replace(\" \", \"_\")\n",
    "    return re.sub(r\"[^\\w_.]\", \"\", filename)\n",
    "\n",
    "\n",
    "def process_html_files_directory(input_dir, output_dir):\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    files = list(input_path.glob(\"*.xls\"))\n",
    "\n",
    "    print(f\"Found {len(files)} .xls files to process\")\n",
    "\n",
    "    successful_files = []\n",
    "    failed_files = []\n",
    "    all_departamentos = defaultdict(list)\n",
    "\n",
    "    for file_path in files:\n",
    "        result = parse_html_excel_file(file_path)\n",
    "\n",
    "        if result[\"success\"]:\n",
    "            df = result[\"data\"]\n",
    "\n",
    "            departamentos = []\n",
    "            for departamento, group in df.groupby(\"DEPARTAMENTO\"):\n",
    "                filename = f\"datos_{sanitize_filename(departamento)}.csv\"\n",
    "\n",
    "                output_file = output_path / filename\n",
    "                group.to_csv(output_file, index=False)\n",
    "\n",
    "                departamentos.append(\n",
    "                    {\"name\": departamento, \"filename\": filename, \"rows\": len(group)}\n",
    "                )\n",
    "\n",
    "                all_departamentos[departamento].append(\n",
    "                    {\n",
    "                        \"source_file\": file_path.name,\n",
    "                        \"csv_file\": filename,\n",
    "                        \"rows\": len(group),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            successful_files.append(\n",
    "                {\n",
    "                    \"file\": file_path.name,\n",
    "                    \"departamentos\": departamentos,\n",
    "                    \"total_rows\": len(df),\n",
    "                }\n",
    "            )\n",
    "\n",
    "            print(f\"  ‚úÖ Processed {file_path.name}: Created {len(departamentos)} CSVs.\")\n",
    "\n",
    "        else:\n",
    "            failed_files.append({\"file\": file_path.name, \"error\": result[\"error\"]})\n",
    "            print(f\"  ‚ùå Failed {file_path.name}: {result['error']}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    print(f\"\\nTotal files: {len(files)}\")\n",
    "    print(f\"‚úÖ Successful: {len(successful_files)}\")\n",
    "    print(f\"‚ùå Failed: {len(failed_files)}\")\n",
    "\n",
    "    # The detailed successful/failed files lists will only be printed if there are successful/failed files.\n",
    "    # The summary already gives a count, so the repetition for successful files is removed here.\n",
    "    # The detailed list for failed files remains as it provides useful error messages.\n",
    "    if failed_files:\n",
    "        print(f\"\\n‚ùå FAILED FILES:\")\n",
    "        for item in failed_files:\n",
    "            print(f\"  - {item['file']}: {item['error']}\")\n",
    "\n",
    "    duplicates = {\n",
    "        name: sources\n",
    "        for name, sources in all_departamentos.items()\n",
    "        if len(sources) > 1\n",
    "    }\n",
    "    if duplicates:\n",
    "        print(f\"\\n‚ö†Ô∏è DUPLICATE DEPARTAMENTOS:\")\n",
    "        for dept_name, sources in duplicates.items():\n",
    "            print(f\"  {dept_name}: appears in {len(sources)} files\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ No duplicate departamentos found\")\n",
    "\n",
    "\n",
    "test_result = parse_html_excel_file(\"data/raw/establecimiento.xls\")\n",
    "if test_result[\"success\"]:\n",
    "    print(\"\\nSingle file test successful!\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PROCESSING ALL FILES\")\n",
    "    print(\"=\" * 60)\n",
    "    process_html_files_directory(\"data/raw\", \"data/csv\")\n",
    "else:\n",
    "    print(f\"‚ùå Single file test failed: {test_result['error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e96a1",
   "metadata": {},
   "source": [
    "## .csv a DataFrames\n",
    "Luego de haber creado los archivos, podemos cargarlos a DataFrames para realizar el an√°lisis necesario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bd3c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 CSV files\n",
      "Loaded 23 datasets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load all CSV files\n",
    "csv_dir = Path(\"data/csv\")\n",
    "csv_files = list(csv_dir.glob(\"*.csv\"))\n",
    "\n",
    "print(f\"Found {len(csv_files)} CSV files\")\n",
    "\n",
    "# Load all datasets\n",
    "datasets = {}\n",
    "for csv_file in csv_files:\n",
    "    dataset_name = csv_file.stem\n",
    "    datasets[dataset_name] = pd.read_csv(csv_file)\n",
    "    \n",
    "print(f\"Loaded {len(datasets)} datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9176a2",
   "metadata": {},
   "source": [
    "# Descripci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afad22cb",
   "metadata": {},
   "source": [
    "## Filas y Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09701424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Shapes:\n",
      "                 dataset  rows  columns\n",
      "8        datos_guatemala  1036       17\n",
      "11  datos_ciudad_capital   864       17\n",
      "3       datos_san_marcos   431       17\n",
      "7        datos_escuintla   393       17\n",
      "5   datos_quetzaltenango   365       17\n",
      "14   datos_chimaltenango   300       17\n",
      "20   datos_suchitepequez   296       17\n",
      "21         datos_jutiapa   296       17\n",
      "15   datos_huehuetenango   295       17\n",
      "2     datos_alta_verapaz   294       17\n",
      "13          datos_izabal   273       17\n",
      "17      datos_retalhuleu   272       17\n",
      "18           datos_peten   270       17\n",
      "1     datos_sacatepequez   208       17\n",
      "16          datos_quiche   184       17\n",
      "0       datos_chiquimula   136       17\n",
      "6       datos_santa_rosa   133       17\n",
      "12          datos_jalapa   121       17\n",
      "22          datos_solola   111       17\n",
      "9      datos_el_progreso    97       17\n",
      "19    datos_baja_verapaz    94       17\n",
      "4           datos_zacapa    70       17\n",
      "10     datos_totonicapan    51       17\n",
      "\n",
      "üìà Summary:\n",
      "Total rows across all datasets: 6,590\n",
      "Average rows per dataset: 287\n",
      "Min/Max rows: 51 / 1036\n"
     ]
    }
   ],
   "source": [
    "shape_info = []\n",
    "for name, df in datasets.items():\n",
    "    shape_info.append({\n",
    "        'dataset': name,\n",
    "        'rows': df.shape[0],\n",
    "        'columns': df.shape[1]\n",
    "    })\n",
    "\n",
    "shape_df = pd.DataFrame(shape_info)\n",
    "print(\"üìä Dataset Shapes:\")\n",
    "print(shape_df.sort_values('rows', ascending=False))\n",
    "\n",
    "print(f\"\\nüìà Summary:\")\n",
    "print(f\"Total rows across all datasets: {shape_df['rows'].sum():,}\")\n",
    "print(f\"Average rows per dataset: {shape_df['rows'].mean():.0f}\")\n",
    "print(f\"Min/Max rows: {shape_df['rows'].min()} / {shape_df['rows'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bd8fd4",
   "metadata": {},
   "source": [
    "## Integridad de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5fef65",
   "metadata": {},
   "source": [
    "### Consistencia en Nombres de Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e31a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Standard columns (17):\n",
      "   1. CODIGO\n",
      "   2. DISTRITO\n",
      "   3. DEPARTAMENTO\n",
      "   4. MUNICIPIO\n",
      "   5. ESTABLECIMIENTO\n",
      "   6. DIRECCION\n",
      "   7. TELEFONO\n",
      "   8. SUPERVISOR\n",
      "   9. DIRECTOR\n",
      "  10. NIVEL\n",
      "  11. SECTOR\n",
      "  12. AREA\n",
      "  13. STATUS\n",
      "  14. MODALIDAD\n",
      "  15. JORNADA\n",
      "  16. PLAN\n",
      "  17. DEPARTAMENTAL\n"
     ]
    }
   ],
   "source": [
    "all_columns = []\n",
    "column_consistency = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    columns = list(df.columns)\n",
    "    all_columns.append(columns)\n",
    "    column_consistency[name] = columns\n",
    "\n",
    "first_columns = all_columns[0]\n",
    "all_same = all(columns == first_columns for columns in all_columns)\n",
    "\n",
    "if all_same:\n",
    "    print(f\"\\n‚úÖ Standard columns ({len(first_columns)}):\")\n",
    "    for i, col in enumerate(first_columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Column differences found:\")\n",
    "    for name, columns in column_consistency.items():\n",
    "        if columns != first_columns:\n",
    "            print(f\"  {name}: {columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a54d5d4",
   "metadata": {},
   "source": [
    "### Encoding Problem√°tico\n",
    "Como mencionamos anteriormente, el encoding de los archivos originales era distinto de \"utf-8\". Nos dimos cuenta al realizar el an√°lisis sobre el encoding problem√°tico, sin embargo al cambiarlo dentro de la funci√≥n anterior logramos correr con √©xito este an√°lisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "330170f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ No encoding issues found (char: 'ÔøΩ')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "problematic_char = \"ÔøΩ\"\n",
    "all_problematic_samples = defaultdict(list)\n",
    "issue_found = False\n",
    "\n",
    "for dataset_name, df in datasets.items():\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            str_series = df[col].astype(str) \n",
    "            \n",
    "            contains_char_mask = str_series.str.contains(problematic_char, na=False)\n",
    "            \n",
    "            if contains_char_mask.any():\n",
    "                issue_found = True\n",
    "                current_samples = str_series[contains_char_mask].unique().tolist()\n",
    "                for sample_val in current_samples:\n",
    "                    if len(all_problematic_samples[col]) < 5:\n",
    "                        all_problematic_samples[col].append(sample_val)\n",
    "\n",
    "\n",
    "if issue_found:\n",
    "    print(f\"‚ùå Encoding issues found (char: '{problematic_char}'):\")\n",
    "    sorted_cols_with_issues = sorted(all_problematic_samples.keys()) \n",
    "\n",
    "    for col in sorted_cols_with_issues:\n",
    "        samples = all_problematic_samples[col]\n",
    "        print(f\"  Column '{col}':\")\n",
    "        for val in samples:\n",
    "            print(f\"    ‚Ä¢ {val}\")\n",
    "else:\n",
    "    print(f\"‚úÖ No encoding issues found (char: '{problematic_char}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d679f59",
   "metadata": {},
   "source": [
    "# An√°lisis de Variables\n",
    "Las variables que m√°s operaciones de limpieza necesitan son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1129942-f7f7-4b02-898b-85e15159e4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing (%)</th>\n",
       "      <th>unique_values</th>\n",
       "      <th>sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CODIGO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6590</td>\n",
       "      <td>[20-01-0024-46, 20-01-0029-46, 20-01-0030-46, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISTRITO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620</td>\n",
       "      <td>[20-001, 20-024, 20-027, 99-001, 20-030]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEPARTAMENTO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>[CHIQUIMULA, SACATEPEQUEZ, ALTA VERAPAZ, SAN M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUNICIPIO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>343</td>\n",
       "      <td>[CHIQUIMULA, SAN JOSE LA ARADA, SAN JUAN ERMIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTABLECIMIENTO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3779</td>\n",
       "      <td>[ESCUELA DE CIENCIAS COMERCIALES NOCTURNA, INS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIRECCION</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4428</td>\n",
       "      <td>[10A. AVENIDA 3-71 ZONA 1, 2A CALLE ENTRE 11 Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TELEFONO</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4208</td>\n",
       "      <td>[79422150.0, 79420395.0, 41942927.0, 79420290....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>598</td>\n",
       "      <td>[CESAR ADALBERTO NOGUERA JACOME, SILVIA MARILE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3860</td>\n",
       "      <td>[H√âCTOR ALIDIO CERON BRENES, ROMEO RIVERA CHAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NIVEL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[DIVERSIFICADO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SECTOR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>[OFICIAL, PRIVADO, COOPERATIVA, MUNICIPAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AREA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>[URBANA, RURAL, SIN ESPECIFICAR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>STATUS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[ABIERTA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MODALIDAD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>[MONOLINGUE, BILINGUE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JORNADA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>[NOCTURNA, VESPERTINA, DOBLE, MATUTINA, SIN JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PLAN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>[DIARIO(REGULAR), FIN DE SEMANA, A DISTANCIA, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEPARTAMENTAL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[CHIQUIMULA, SACATEP√âQUEZ, ALTA VERAPAZ, SAN M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             column  missing (%)  unique_values  \\\n",
       "0            CODIGO          0.0           6590   \n",
       "1          DISTRITO          0.0            620   \n",
       "2      DEPARTAMENTO          0.0             23   \n",
       "3         MUNICIPIO          0.0            343   \n",
       "4   ESTABLECIMIENTO          0.0           3779   \n",
       "5         DIRECCION          0.0           4428   \n",
       "6          TELEFONO          0.0           4208   \n",
       "7        SUPERVISOR          0.0            598   \n",
       "8          DIRECTOR          0.0           3860   \n",
       "9             NIVEL          0.0              1   \n",
       "10           SECTOR          0.0              4   \n",
       "11             AREA          0.0              3   \n",
       "12           STATUS          0.0              1   \n",
       "13        MODALIDAD          0.0              2   \n",
       "14          JORNADA          0.0              6   \n",
       "15             PLAN          0.0             12   \n",
       "16    DEPARTAMENTAL          0.0             26   \n",
       "\n",
       "                                        sample_values  \n",
       "0   [20-01-0024-46, 20-01-0029-46, 20-01-0030-46, ...  \n",
       "1            [20-001, 20-024, 20-027, 99-001, 20-030]  \n",
       "2   [CHIQUIMULA, SACATEPEQUEZ, ALTA VERAPAZ, SAN M...  \n",
       "3   [CHIQUIMULA, SAN JOSE LA ARADA, SAN JUAN ERMIT...  \n",
       "4   [ESCUELA DE CIENCIAS COMERCIALES NOCTURNA, INS...  \n",
       "5   [10A. AVENIDA 3-71 ZONA 1, 2A CALLE ENTRE 11 Y...  \n",
       "6   [79422150.0, 79420395.0, 41942927.0, 79420290....  \n",
       "7   [CESAR ADALBERTO NOGUERA JACOME, SILVIA MARILE...  \n",
       "8   [H√âCTOR ALIDIO CERON BRENES, ROMEO RIVERA CHAC...  \n",
       "9                                     [DIVERSIFICADO]  \n",
       "10         [OFICIAL, PRIVADO, COOPERATIVA, MUNICIPAL]  \n",
       "11                   [URBANA, RURAL, SIN ESPECIFICAR]  \n",
       "12                                          [ABIERTA]  \n",
       "13                             [MONOLINGUE, BILINGUE]  \n",
       "14  [NOCTURNA, VESPERTINA, DOBLE, MATUTINA, SIN JO...  \n",
       "15  [DIARIO(REGULAR), FIN DE SEMANA, A DISTANCIA, ...  \n",
       "16  [CHIQUIMULA, SACATEP√âQUEZ, ALTA VERAPAZ, SAN M...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_stats = []\n",
    "\n",
    "for col in first_columns:\n",
    "    col_data = []\n",
    "    for name, df in datasets.items():\n",
    "        if col in df.columns:\n",
    "            series = df[col].astype(str).str.strip()\n",
    "            col_data.extend(series)\n",
    "\n",
    "    series_all = pd.Series(col_data)\n",
    "    n_total = len(series_all)\n",
    "    n_missing = (series_all == \"\").sum() + series_all.isna().sum()\n",
    "    n_unique = series_all.nunique()\n",
    "    \n",
    "    summary_stats.append({\n",
    "        \"column\": col,\n",
    "        \"missing (%)\": round((n_missing / n_total) * 100, 2),\n",
    "        \"unique_values\": n_unique,\n",
    "        \"sample_values\": series_all.dropna().unique()[:5].tolist()\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_stats)\n",
    "df_summary.sort_values(\"missing (%)\", ascending=False, inplace=True)\n",
    "\n",
    "display(df_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8735b0",
   "metadata": {},
   "source": [
    "## C√≥digo\n",
    "Este valor parece ser un identificador √∫nico, queremos explorar las siguientes propiedades:\n",
    "- Unicidad: Este c√≥digo es √∫nico dentro de su respectivo dataset o todos?\n",
    "- Formato: Es consistente el formato en todos los datasets? Existen errores de digitaci√≥n?\n",
    "- Valores Faltantes: Existen valores faltantes?\n",
    "- Nos ayuda a identificar √∫nicamente alg√∫n otro valor?\n",
    "\n",
    "Debido a esto, queremos realizar los siguientes pasos de limpieza:\n",
    "\n",
    "- Identificar unicidad del c√≥digo\n",
    "- Identificar Valores Faltantes\n",
    "- Revisar errores de digitaci√≥n, c√≥mo lo pueden ser whitespaces o formato incongruente\n",
    "- Identificar si nos puede ayudar a identificar otras variables para verificar errores de digitaci√≥n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a4fee8",
   "metadata": {},
   "source": [
    "## Distrito\n",
    "Este valor parece ser un identificador geogr√°fico, siguiendo un formato XX-YYY. Queremos explorar las siguientes propiedades\n",
    "- Formato: Es consistente el formato?\n",
    "- Valores Faltantes: Existen valores faltantes dentro de los datasets?\n",
    "- Nos ayuda a identificar √∫nicamente alg√∫n otro valor?\n",
    "\n",
    "Debido a esto, queremos realizar los siguientes pasos de limpieza:\n",
    "\n",
    "- Identificar valores faltantes\n",
    "- Revisar errores de digitaci√≥n\n",
    "- Enforzar un formato consistente\n",
    "- Identificar si nos puede ayuda a verificar la consistencia de Municipio o alg√∫n otro valor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5415d62",
   "metadata": {},
   "source": [
    "## Departamento\n",
    "\n",
    "Ya que los DataFrames se encuentran divididos por departamento, esta entrada deber√≠a ser completamente consistente. Adem√°s, podemos proponer los siguientes pasos para una mayor consistencia:\n",
    "\n",
    "- Identificar el valor RAW m√°s com√∫n, ya que un error de digitaci√≥n ser√≠a menos frecuente\n",
    "- Tomar ese valor y realizar las siguientes transformaciones\n",
    "    - Conversi√≥n a min√∫sculas\n",
    "    - Reemplazo de espacios por _\n",
    "    - Aplicar a todas las columnas de cada DF individual\n",
    "- Aplicar OHE luego de mergear los DFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012e2a71",
   "metadata": {},
   "source": [
    "## Municipio\n",
    "\n",
    "Este valor representa la divisi√≥n pol√≠tica a nivel municipal. Dado que se usa como categor√≠a geogr√°fica clave, es esencial asegurar consistencia.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Formato: ¬øSe encuentra todo en may√∫sculas? ¬øHay tildes inconsistentes?\n",
    "- Valores Faltantes: Confirmar si hay celdas vac√≠as o marcadas incorrectamente.\n",
    "- Relaci√≥n con otros campos: ¬øEl municipio concuerda con el departamento correspondiente?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Convertir todo el texto a may√∫sculas (.str.upper()).\n",
    "- Eliminar espacios extra antes o despu√©s (.str.strip()).\n",
    "- Normalizar tildes y caracteres especiales si necesario.\n",
    "- Validar los municipios contra una lista oficial por departamento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddb656",
   "metadata": {},
   "source": [
    "## Establecimiento\n",
    "\n",
    "Nombre propio de la instituci√≥n educativa. Puede contener muchas variantes tipogr√°ficas y estil√≠sticas que dificultan an√°lisis posteriores.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Formato: ¬øSe mantiene una capitalizaci√≥n consistente?\n",
    "- Valores Faltantes: ¬øHay registros sin nombre?\n",
    "- Redundancia o duplicaci√≥n: ¬øExisten nombres duplicados con leves diferencias?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Capitalizar nombres con .str.title() para uniformidad visual.\n",
    "- Eliminar espacios repetidos entre palabras.\n",
    "- Remover puntuaci√≥n innecesaria.\n",
    "- Establecer reglas para abreviaciones comunes si se encuentran (ej. \"Inst.\" por \"Instituto\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0133d64-4ad1-4159-83eb-9c65b77ad67f",
   "metadata": {},
   "source": [
    "## DIRECCI√ìN\n",
    "\n",
    "Campo libre con alta variabilidad. Las direcciones pueden contener m√∫ltiples abreviaturas, puntuaci√≥n, y errores de digitaci√≥n.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "- Formato: ¬øExisten patrones comunes? ¬øSe usan abreviaturas (CALLE, AV, etc.)?\n",
    "- Valores inconsistentes: ¬øUso indistinto de may√∫sculas, puntuaci√≥n, acentos?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "- Normalizar a may√∫sculas (.str.upper()).\n",
    "- Crear reglas de sustituci√≥n para abreviaturas frecuentes (ej. AVENIDA ‚Üí AV.).\n",
    "- Quitar s√≠mbolos innecesarios y estandarizar signos de puntuaci√≥n.\n",
    "- Opcional: usar expresiones regulares para separar partes de la direcci√≥n (calle, n√∫mero, zona, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bff941-e337-4303-aa50-85cb514fc243",
   "metadata": {},
   "source": [
    "## TEL√âFONO\n",
    "\n",
    "Campo num√©rico con alta variabilidad en formato. Puede contener n√∫meros concatenados, separadores o caracteres no num√©ricos.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "- Formato: ¬øTodos los valores contienen exactamente 8 d√≠gitos? ¬øHay m√∫ltiples n√∫meros por celda?\n",
    "- Errores: ¬øCaracteres no num√©ricos? ¬øEspacios o signos innecesarios?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Remover todos los caracteres no num√©ricos con re.sub(r\"\\D\", \"\", telefono).\n",
    "- Validar longitud est√°ndar (8 d√≠gitos en Guatemala).\n",
    "- Si hay m√∫ltiples n√∫meros, dividir y elegir el primero o guardarlos como lista."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968f088-68f0-45d5-8365-9ab8c5208b4d",
   "metadata": {},
   "source": [
    "## SUPERVISOR\n",
    "\n",
    "Nombre del supervisor responsable. Puede presentar variaciones por uso de tildes, may√∫sculas, y errores ortogr√°ficos menores.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Formato: ¬øMay√∫sculas/min√∫sculas inconsistentes?\n",
    "- Duplicaci√≥n: ¬øUn mismo nombre aparece escrito de m√∫ltiples formas?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Capitalizar con .str.title() para uniformidad.\n",
    "- Remover espacios dobles y caracteres extra√±os.\n",
    "- Normalizar tildes si es necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e67f16-f9a8-4fdc-9a0f-5e188d88a914",
   "metadata": {},
   "source": [
    "## DIRECTOR\n",
    "\n",
    "Similar al campo de supervisor, representa nombres propios con riesgos similares de inconsistencia.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Aplicar los mismos criterios que SUPERVISOR.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Igual estrategia de capitalizaci√≥n, limpieza de espacios, y normalizaci√≥n de caracteres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8203578-43ba-44f3-b112-e7e765512022",
   "metadata": {},
   "source": [
    "## NIVEL\n",
    "Este campo tiene un √∫nico valor: \"DIVERSIFICADO\".\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Verificar que efectivamente todos los valores son iguales.\n",
    "- Confirmar si es √∫til conservar esta columna.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Si es redundante, considerar eliminarla para evitar ruido en an√°lisis futuros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17b7908-d5b2-4bcf-8dba-479bc1d64b9f",
   "metadata": {},
   "source": [
    "## SECTOR\n",
    "\n",
    "Categor√≠a con pocos valores √∫nicos. Se espera valores como \"OFICIAL\", \"PRIVADO\", etc.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- ¬øMay√∫sculas o min√∫sculas inconsistentes?\n",
    "- ¬øErrores ortogr√°ficos?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Convertir todo a may√∫sculas y eliminar espacios (.str.upper().str.strip()).\n",
    "- Validar los valores contra un conjunto permitido: {OFICIAL, PRIVADO, MUNICIPAL, COOPERATIVA}.\n",
    "- Convertir a tipo Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f5b092-16d1-4790-be2e-4976d8533f41",
   "metadata": {},
   "source": [
    "## √ÅREA\n",
    "Identifica si la instituci√≥n est√° en zona rural o urbana.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "- Confirmar que los valores son: URBANA, RURAL, SIN ESPECIFICAR.\n",
    "- Verificar errores de digitaci√≥n o combinaciones no v√°lidas.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "- Uniformar may√∫sculas (.str.upper()).\n",
    "- Reemplazar variantes de ‚Äúsin especificar‚Äù por un valor est√°ndar (ej. \"DESCONOCIDO\").\n",
    "- Convertir a Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fb68b7",
   "metadata": {},
   "source": [
    "## STATUS\n",
    "Campo con un √∫nico valor: \"ABIERTA\".\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "Verificar si realmente todos los valores son iguales.\n",
    "\n",
    "Evaluar su utilidad en an√°lisis futuros.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Eliminar si es redundante (sin variabilidad)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4aaf2",
   "metadata": {},
   "source": [
    "## MODALIDAD\n",
    "Pocos valores √∫nicos: \"MONOLINGUE\", \"BILINGUE\".\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "Verificar may√∫sculas y tildes.\n",
    "\n",
    "Validar que no existan variantes escritas incorrectamente.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Uniformar may√∫sculas y acentos (.str.upper()).\n",
    "\n",
    "Reemplazar variantes con un mapeo fijo.\n",
    "\n",
    "Convertir a Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963c401d",
   "metadata": {},
   "source": [
    "## JORNADA\n",
    "Categor√≠a horaria. Existen valores como ‚ÄúMATUTINA‚Äù, ‚ÄúVESPERTINA‚Äù, ‚ÄúDOBLE‚Äù, ‚ÄúNOCHE‚Äù, etc.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "Verificar consistencia de t√©rminos.\n",
    "\n",
    "Identificar redundancias o t√©rminos similares con diferencias menores.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Normalizar formato (.str.upper().str.strip()).\n",
    "\n",
    "Mapear variantes a un conjunto est√°ndar.\n",
    "\n",
    "Eliminar signos extra o abreviaciones inconsistentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5070a90f",
   "metadata": {},
   "source": [
    "## PLAN\n",
    "Puede incluir valores con par√©ntesis, como ‚ÄúDIARIO(REGULAR)‚Äù, que dificultan an√°lisis.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "¬øHay signos innecesarios como par√©ntesis o guiones?\n",
    "\n",
    "¬øHay t√©rminos redundantes?\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Eliminar par√©ntesis y su contenido con str.replace(r'\\(.*?\\)', '').\n",
    "\n",
    "Eliminar espacios extra y convertir a may√∫sculas.\n",
    "\n",
    "Validar valores contra una lista limpia predefinida.\n",
    "\n",
    "Convertir a Categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b50ae",
   "metadata": {},
   "source": [
    "## DEPARTAMENTAL\n",
    "Representa una divisi√≥n regional administrativa.\n",
    "\n",
    "Exploraci√≥n a realizar:\n",
    "\n",
    "Verificar may√∫sculas, errores tipogr√°ficos.\n",
    "\n",
    "Confirmar que corresponde con el valor del campo DEPARTAMENTO.\n",
    "\n",
    "Pasos de limpieza propuestos:\n",
    "\n",
    "Uniformar texto (.str.upper().str.strip()).\n",
    "\n",
    "Validar contra un listado oficial del MINEDUC.\n",
    "\n",
    "Opcional: cruzar con DEPARTAMENTO para consistencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef7d0f",
   "metadata": {},
   "source": [
    "## Definici√≥n de funciones para limpieza de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a07e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_establecimiento(df):\n",
    "\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean['ESTABLECIMIENTO'] = (df_clean['ESTABLECIMIENTO']\n",
    "                                  .str.replace('\"\"', '\"', regex=False)\n",
    "                                  .str.replace('\"', '', regex=False))\n",
    "    \n",
    "    print(f\" ESTABLECIMIENTO limpiado: {(df['ESTABLECIMIENTO'] != df_clean['ESTABLECIMIENTO']).sum()} registros corregidos\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def clean_plan(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean['PLAN'] = (df_clean['PLAN']\n",
    "                       .str.replace(r'\\s*\\([^)]*\\)', '', regex=True)\n",
    "                       .str.strip())\n",
    "    \n",
    "    print(f\" PLAN limpiado: {(df['PLAN'] != df_clean['PLAN']).sum()} registros corregidos\")\n",
    "    print(f\"   Valores √∫nicos despu√©s de limpieza: {df_clean['PLAN'].unique()}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def clean_telefono(df):\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    def process_phone(phone):\n",
    "        if pd.isna(phone) or phone == '':\n",
    "            return None\n",
    "            \n",
    "        phone_str = str(phone)\n",
    "        \n",
    "        if '-' in phone_str:\n",
    "            phone_str = phone_str.split('-')[0]\n",
    "        \n",
    "        numbers_only = re.sub(r'[^0-9]', '', phone_str)\n",
    "        \n",
    "        if len(numbers_only) == 8:\n",
    "            return numbers_only\n",
    "        elif len(numbers_only) == 7:\n",
    "            if numbers_only[0] in ['3', '4', '5']:\n",
    "                return '0' + numbers_only\n",
    "            else:\n",
    "                return numbers_only\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    df_clean['TELEFONO'] = df_clean['TELEFONO'].apply(process_phone)\n",
    "    \n",
    "    valid_phones = df_clean['TELEFONO'].notna().sum()\n",
    "    total_phones = len(df_clean)\n",
    "    corrected = (df['TELEFONO'].astype(str) != df_clean['TELEFONO'].astype(str)).sum()\n",
    "    \n",
    "    print(f\"TELEFONO limpiado: {corrected} registros corregidos\")\n",
    "    print(f\"   Tel√©fonos v√°lidos: {valid_phones}/{total_phones} ({valid_phones/total_phones*100:.1f}%)\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "def apply_basic_cleaning(df):\n",
    "\n",
    "    print(f\"üßπ Limpiando dataset con {len(df)} registros...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean = clean_establecimiento(df_clean)\n",
    "    df_clean = clean_plan(df_clean)\n",
    "    df_clean = clean_telefono(df_clean)\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(f\"Limpieza completada\")\n",
    "    \n",
    "    return df_clean\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ffb41a",
   "metadata": {},
   "source": [
    "### Generaci√≥n de encoding categ√≥rico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202855d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_categorical_encoding(df):\n",
    "    df_encoded = df.copy()\n",
    "    \n",
    "    categorical_fields = ['SECTOR', 'AREA', 'MODALIDAD', 'JORNADA', 'PLAN']\n",
    "    \n",
    "    print(\"Creando variables dummy...\")\n",
    "    \n",
    "    for field in categorical_fields:\n",
    "        if field in df_encoded.columns:\n",
    "            dummies = pd.get_dummies(df_encoded[field], prefix=field.lower())\n",
    "            df_encoded = pd.concat([df_encoded, dummies], axis=1)\n",
    "            print(f\"{field}: {len(dummies.columns)} categor√≠as\")\n",
    "    \n",
    "    df_encoded['es_publico'] = df_encoded['SECTOR'].isin(['OFICIAL', 'MUNICIPAL']).astype(int)\n",
    "    df_encoded['es_rural'] = (df_encoded['AREA'] == 'RURAL').astype(int)\n",
    "    df_encoded['tiene_telefono'] = df_encoded['TELEFONO'].notna().astype(int)\n",
    "    \n",
    "    print(f\"Variables adicionales: es_publico, es_rural, tiene_telefono\")\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "def clean_and_prepare_dataset(file_path):\n",
    "    print(f\"Procesando: {Path(file_path).name}\")\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Registros originales: {len(df)}\")\n",
    "\n",
    "    df_clean = apply_basic_cleaning(df)\n",
    "    \n",
    "    df_encoded = create_categorical_encoding(df_clean)\n",
    "    \n",
    "    print(f\"Registros finales: {len(df_encoded)}\")\n",
    "    print(f\"Columnas finales: {len(df_encoded.columns)}\")\n",
    "    \n",
    "    return df_clean, df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62398bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_datasets(input_dir=\"data/csv\", output_dir=\"data/cleaned\"):\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    csv_files = list(input_path.glob(\"*.csv\"))\n",
    "    print(f\"üöÄ Procesando {len(csv_files)} archivos CSV...\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    all_clean_data = []\n",
    "    all_encoded_data = []\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        try:\n",
    "            df_clean, df_encoded = clean_and_prepare_dataset(csv_file)\n",
    "            \n",
    "            clean_output = output_path / f\"{csv_file.stem}_clean.csv\"\n",
    "            df_clean.to_csv(clean_output, index=False)\n",
    "            \n",
    "            all_clean_data.append(df_clean)\n",
    "            all_encoded_data.append(df_encoded)\n",
    "            \n",
    "            print(f\"Guardado: {clean_output.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {csv_file.name}: {str(e)}\")\n",
    "    \n",
    "    if all_clean_data:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"üìä Creando datasets combinados...\")\n",
    "        \n",
    "        combined_clean = pd.concat(all_clean_data, ignore_index=True)\n",
    "        combined_clean_path = output_path / \"mineduc_combined_clean.csv\"\n",
    "        combined_clean.to_csv(combined_clean_path, index=False)\n",
    "        \n",
    "        combined_encoded = pd.concat(all_encoded_data, ignore_index=True)\n",
    "        combined_encoded_path = output_path / \"mineduc_combined_encoded.csv\"\n",
    "        combined_encoded.to_csv(combined_encoded_path, index=False)\n",
    "        \n",
    "        print(f\"‚úÖ Dataset limpio combinado: {len(combined_clean)} registros\")\n",
    "        print(f\"   üìÅ {combined_clean_path}\")\n",
    "        print(f\"‚úÖ Dataset codificado combinado: {len(combined_encoded)} registros, {len(combined_encoded.columns)} columnas\")\n",
    "        print(f\"   üìÅ {combined_encoded_path}\")\n",
    "        \n",
    "        return combined_clean, combined_encoded\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def generate_summary_report(df):\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REPORTE FINAL DE DATOS LIMPIOS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"Registros totales: {len(df):,}\")\n",
    "    print(f\"Establecimientos √∫nicos: {df['ESTABLECIMIENTO'].nunique():,}\")\n",
    "    print(f\"Municipios √∫nicos: {df['MUNICIPIO'].nunique()}\")\n",
    "    print(f\"Departamentos √∫nicos: {df['DEPARTAMENTO'].nunique()}\")\n",
    "    \n",
    "    print(f\"\\nTel√©fonos v√°lidos: {df['TELEFONO'].notna().sum():,} ({df['TELEFONO'].notna().mean()*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nDistribuci√≥n por SECTOR:\")\n",
    "    sector_dist = df['SECTOR'].value_counts()\n",
    "    for sector, count in sector_dist.items():\n",
    "        print(f\"   {sector}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nDistribuci√≥n por √ÅREA:\")\n",
    "    area_dist = df['AREA'].value_counts()\n",
    "    for area, count in area_dist.items():\n",
    "        print(f\"   {area}: {count:,} ({count/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nDistribuci√≥n por MODALIDAD:\")\n",
    "    modalidad_dist = df['MODALIDAD'].value_counts()\n",
    "    for modalidad, count in modalidad_dist.items():\n",
    "        print(f\"   {modalidad}: {count:,} ({count/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be86158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Procesando 23 archivos CSV...\n",
      "======================================================================\n",
      "üìÇ Procesando: datos_chiquimula.csv\n",
      "   Registros originales: 136\n",
      "üßπ Limpiando dataset con 136 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 17 registros corregidos\n",
      " PLAN limpiado: 104 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 136 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 0/136 (0.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 6 categor√≠as\n",
      "PLAN: 4 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 136\n",
      "Columnas finales: 38\n",
      "Guardado: datos_chiquimula_clean.csv\n",
      "üìÇ Procesando: datos_sacatepequez.csv\n",
      "   Registros originales: 208\n",
      "üßπ Limpiando dataset con 208 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 7 registros corregidos\n",
      " PLAN limpiado: 170 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 1 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 208/208 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 208\n",
      "Columnas finales: 38\n",
      "Guardado: datos_sacatepequez_clean.csv\n",
      "üìÇ Procesando: datos_alta_verapaz.csv\n",
      "   Registros originales: 294\n",
      "üßπ Limpiando dataset con 294 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 33 registros corregidos\n",
      " PLAN limpiado: 228 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 8 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 288/294 (98.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 294\n",
      "Columnas finales: 38\n",
      "Guardado: datos_alta_verapaz_clean.csv\n",
      "üìÇ Procesando: datos_san_marcos.csv\n",
      "   Registros originales: 431\n",
      "üßπ Limpiando dataset con 431 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 142 registros corregidos\n",
      " PLAN limpiado: 365 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 431 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 1/431 (0.2%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 6 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 431\n",
      "Columnas finales: 39\n",
      "Guardado: datos_san_marcos_clean.csv\n",
      "üìÇ Procesando: datos_zacapa.csv\n",
      "   Registros originales: 70\n",
      "üßπ Limpiando dataset con 70 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 23 registros corregidos\n",
      " PLAN limpiado: 59 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 0 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 70/70 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 1 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 4 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 70\n",
      "Columnas finales: 36\n",
      "Guardado: datos_zacapa_clean.csv\n",
      "üìÇ Procesando: datos_quetzaltenango.csv\n",
      "   Registros originales: 365\n",
      "üßπ Limpiando dataset con 365 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 98 registros corregidos\n",
      " PLAN limpiado: 308 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 0 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 365/365 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 365\n",
      "Columnas finales: 38\n",
      "Guardado: datos_quetzaltenango_clean.csv\n",
      "üìÇ Procesando: datos_santa_rosa.csv\n",
      "   Registros originales: 133\n",
      "üßπ Limpiando dataset con 133 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 56 registros corregidos\n",
      " PLAN limpiado: 104 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL' 'MIXTO']\n",
      "TELEFONO limpiado: 133 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 0/133 (0.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 1 categor√≠as\n",
      "JORNADA: 6 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 133\n",
      "Columnas finales: 37\n",
      "Guardado: datos_santa_rosa_clean.csv\n",
      "üìÇ Procesando: datos_escuintla.csv\n",
      "   Registros originales: 393\n",
      "üßπ Limpiando dataset con 393 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 75 registros corregidos\n",
      " PLAN limpiado: 303 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 3 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 391/393 (99.5%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 6 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 393\n",
      "Columnas finales: 39\n",
      "Guardado: datos_escuintla_clean.csv\n",
      "üìÇ Procesando: datos_guatemala.csv\n",
      "   Registros originales: 1036\n",
      "üßπ Limpiando dataset con 1036 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 118 registros corregidos\n",
      " PLAN limpiado: 778 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'SEMIPRESENCIAL' 'A DISTANCIA'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 11 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 1031/1036 (99.5%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 1036\n",
      "Columnas finales: 38\n",
      "Guardado: datos_guatemala_clean.csv\n",
      "üìÇ Procesando: datos_el_progreso.csv\n",
      "   Registros originales: 97\n",
      "üßπ Limpiando dataset con 97 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 12 registros corregidos\n",
      " PLAN limpiado: 77 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 97 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 1/97 (1.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 1 categor√≠as\n",
      "JORNADA: 4 categor√≠as\n",
      "PLAN: 4 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 97\n",
      "Columnas finales: 35\n",
      "Guardado: datos_el_progreso_clean.csv\n",
      "üìÇ Procesando: datos_totonicapan.csv\n",
      "   Registros originales: 51\n",
      "üßπ Limpiando dataset con 51 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 28 registros corregidos\n",
      " PLAN limpiado: 44 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'A DISTANCIA' 'SEMIPRESENCIAL' 'FIN DE SEMANA']\n",
      "TELEFONO limpiado: 5 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 51/51 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 4 categor√≠as\n",
      "PLAN: 4 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 51\n",
      "Columnas finales: 35\n",
      "Guardado: datos_totonicapan_clean.csv\n",
      "üìÇ Procesando: datos_ciudad_capital.csv\n",
      "   Registros originales: 864\n",
      "üßπ Limpiando dataset con 864 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 133 registros corregidos\n",
      " PLAN limpiado: 638 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'VIRTUAL A DISTANCIA'\n",
      " 'SEMIPRESENCIAL' 'SABATINO']\n",
      "TELEFONO limpiado: 1 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 864/864 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 3 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 6 categor√≠as\n",
      "PLAN: 6 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 864\n",
      "Columnas finales: 41\n",
      "Guardado: datos_ciudad_capital_clean.csv\n",
      "üìÇ Procesando: datos_jalapa.csv\n",
      "   Registros originales: 121\n",
      "üßπ Limpiando dataset con 121 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 69 registros corregidos\n",
      " PLAN limpiado: 91 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 1 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 121/121 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 1 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 4 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 121\n",
      "Columnas finales: 36\n",
      "Guardado: datos_jalapa_clean.csv\n",
      "üìÇ Procesando: datos_izabal.csv\n",
      "   Registros originales: 273\n",
      "üßπ Limpiando dataset con 273 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 112 registros corregidos\n",
      " PLAN limpiado: 181 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 14 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 273/273 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 4 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 273\n",
      "Columnas finales: 37\n",
      "Guardado: datos_izabal_clean.csv\n",
      "üìÇ Procesando: datos_chimaltenango.csv\n",
      "   Registros originales: 300\n",
      "üßπ Limpiando dataset con 300 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 115 registros corregidos\n",
      " PLAN limpiado: 213 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 7 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 299/300 (99.7%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 6 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 300\n",
      "Columnas finales: 39\n",
      "Guardado: datos_chimaltenango_clean.csv\n",
      "üìÇ Procesando: datos_huehuetenango.csv\n",
      "   Registros originales: 295\n",
      "üßπ Limpiando dataset con 295 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 93 registros corregidos\n",
      " PLAN limpiado: 227 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'INTERCALADO' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 0 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 295/295 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 4 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 295\n",
      "Columnas finales: 36\n",
      "Guardado: datos_huehuetenango_clean.csv\n",
      "üìÇ Procesando: datos_quiche.csv\n",
      "   Registros originales: 184\n",
      "üßπ Limpiando dataset con 184 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 32 registros corregidos\n",
      " PLAN limpiado: 146 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'VIRTUAL A DISTANCIA'\n",
      " 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 1 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 183/184 (99.5%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 6 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 184\n",
      "Columnas finales: 39\n",
      "Guardado: datos_quiche_clean.csv\n",
      "üìÇ Procesando: datos_retalhuleu.csv\n",
      "   Registros originales: 272\n",
      "üßπ Limpiando dataset con 272 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 53 registros corregidos\n",
      " PLAN limpiado: 186 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['FIN DE SEMANA' 'DIARIO' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA' 'SABATINO' 'DOMINICAL']\n",
      "TELEFONO limpiado: 272 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 0/272 (0.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 7 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 272\n",
      "Columnas finales: 40\n",
      "Guardado: datos_retalhuleu_clean.csv\n",
      "üìÇ Procesando: datos_peten.csv\n",
      "   Registros originales: 270\n",
      "üßπ Limpiando dataset con 270 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 104 registros corregidos\n",
      " PLAN limpiado: 197 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 6 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 267/270 (98.9%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 6 categor√≠as\n",
      "PLAN: 4 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 270\n",
      "Columnas finales: 38\n",
      "Guardado: datos_peten_clean.csv\n",
      "üìÇ Procesando: datos_baja_verapaz.csv\n",
      "   Registros originales: 94\n",
      "üßπ Limpiando dataset con 94 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 1 registros corregidos\n",
      " PLAN limpiado: 72 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'SEMIPRESENCIAL' 'A DISTANCIA']\n",
      "TELEFONO limpiado: 2 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 94/94 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 4 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 94\n",
      "Columnas finales: 36\n",
      "Guardado: datos_baja_verapaz_clean.csv\n",
      "üìÇ Procesando: datos_suchitepequez.csv\n",
      "   Registros originales: 296\n",
      "üßπ Limpiando dataset con 296 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 124 registros corregidos\n",
      " PLAN limpiado: 205 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA' 'SABATINO']\n",
      "TELEFONO limpiado: 296 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 2/296 (0.7%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 1 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 6 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 296\n",
      "Columnas finales: 38\n",
      "Guardado: datos_suchitepequez_clean.csv\n",
      "üìÇ Procesando: datos_jutiapa.csv\n",
      "   Registros originales: 296\n",
      "üßπ Limpiando dataset con 296 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 98 registros corregidos\n",
      " PLAN limpiado: 210 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'VIRTUAL A DISTANCIA'\n",
      " 'SEMIPRESENCIAL']\n",
      "TELEFONO limpiado: 296 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 2/296 (0.7%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 4 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 1 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 296\n",
      "Columnas finales: 37\n",
      "Guardado: datos_jutiapa_clean.csv\n",
      "üìÇ Procesando: datos_solola.csv\n",
      "   Registros originales: 111\n",
      "üßπ Limpiando dataset con 111 registros...\n",
      "==================================================\n",
      " ESTABLECIMIENTO limpiado: 30 registros corregidos\n",
      " PLAN limpiado: 98 registros corregidos\n",
      "   Valores √∫nicos despu√©s de limpieza: ['DIARIO' 'FIN DE SEMANA' 'A DISTANCIA' 'SEMIPRESENCIAL'\n",
      " 'VIRTUAL A DISTANCIA']\n",
      "TELEFONO limpiado: 0 registros corregidos\n",
      "   Tel√©fonos v√°lidos: 111/111 (100.0%)\n",
      "==================================================\n",
      "Limpieza completada\n",
      "Creando variables dummy...\n",
      "SECTOR: 3 categor√≠as\n",
      "AREA: 2 categor√≠as\n",
      "MODALIDAD: 2 categor√≠as\n",
      "JORNADA: 5 categor√≠as\n",
      "PLAN: 5 categor√≠as\n",
      "Variables adicionales: es_publico, es_rural, tiene_telefono\n",
      "Registros finales: 111\n",
      "Columnas finales: 37\n",
      "Guardado: datos_solola_clean.csv\n",
      "\n",
      "======================================================================\n",
      "üìä Creando datasets combinados...\n",
      "‚úÖ Dataset limpio combinado: 6590 registros\n",
      "   üìÅ data/cleaned/mineduc_combined_clean.csv\n",
      "‚úÖ Dataset codificado combinado: 6590 registros, 44 columnas\n",
      "   üìÅ data/cleaned/mineduc_combined_encoded.csv\n",
      "\n",
      "============================================================\n",
      "REPORTE FINAL DE DATOS LIMPIOS\n",
      "============================================================\n",
      "Registros totales: 6,590\n",
      "Establecimientos √∫nicos: 3,573\n",
      "Municipios √∫nicos: 343\n",
      "Departamentos √∫nicos: 23\n",
      "\n",
      "Tel√©fonos v√°lidos: 4,917 (74.6%)\n",
      "\n",
      "Distribuci√≥n por SECTOR:\n",
      "   PRIVADO: 5,409 (82.1%)\n",
      "   OFICIAL: 874 (13.3%)\n",
      "   COOPERATIVA: 213 (3.2%)\n",
      "   MUNICIPAL: 94 (1.4%)\n",
      "\n",
      "Distribuci√≥n por √ÅREA:\n",
      "   URBANA: 5,242 (79.5%)\n",
      "   RURAL: 1,347 (20.4%)\n",
      "   SIN ESPECIFICAR: 1 (0.0%)\n",
      "\n",
      "Distribuci√≥n por MODALIDAD:\n",
      "   MONOLINGUE: 6,381 (96.8%)\n",
      "   BILINGUE: 209 (3.2%)\n",
      "\n",
      "¬°Proceso completado exitosamente!\n",
      "Archivos disponibles en: data/cleaned/\n",
      "- Archivos individuales limpios\n",
      "- mineduc_combined_clean.csv (datos limpios)\n",
      "- mineduc_combined_encoded.csv (con variables dummy)\n"
     ]
    }
   ],
   "source": [
    "df_clean, df_encoded = process_all_datasets()\n",
    "    \n",
    "if df_clean is not None:\n",
    "    generate_summary_report(df_clean)\n",
    "    \n",
    "    print(f\"\\n¬°Proceso completado exitosamente!\")\n",
    "    print(f\"Archivos disponibles en: data/cleaned/\")\n",
    "    print(f\"- Archivos individuales limpios\")\n",
    "    print(f\"- mineduc_combined_clean.csv (datos limpios)\")\n",
    "    print(f\"- mineduc_combined_encoded.csv (con variables dummy)\")\n",
    "else:\n",
    "    print(\"No se pudieron procesar los datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cac851b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CODIGO DISTRITO DEPARTAMENTO         MUNICIPIO  \\\n",
      "0     20-01-0024-46   20-001   CHIQUIMULA        CHIQUIMULA   \n",
      "1     20-01-0029-46   20-001   CHIQUIMULA        CHIQUIMULA   \n",
      "2     20-01-0030-46   20-001   CHIQUIMULA        CHIQUIMULA   \n",
      "3     20-01-0031-46   20-024   CHIQUIMULA        CHIQUIMULA   \n",
      "4     20-01-0032-46   20-024   CHIQUIMULA        CHIQUIMULA   \n",
      "...             ...      ...          ...               ...   \n",
      "6585  07-19-0034-46   07-015       SOLOLA  SANTIAGO ATITLAN   \n",
      "6586  07-19-0051-46   07-015       SOLOLA  SANTIAGO ATITLAN   \n",
      "6587  07-19-0065-46   07-015       SOLOLA  SANTIAGO ATITLAN   \n",
      "6588  07-19-0103-46   07-027       SOLOLA  SANTIAGO ATITLAN   \n",
      "6589  07-19-2765-46   07-015       SOLOLA  SANTIAGO ATITLAN   \n",
      "\n",
      "                                        ESTABLECIMIENTO  \\\n",
      "0              ESCUELA DE CIENCIAS COMERCIALES NOCTURNA   \n",
      "1     INSTITUTO DIVERSIFICADO ADS. AL INEB 'DR. DAVI...   \n",
      "2     ESCUELA NACIONAL DE MAESTROS DE EDUCACION MUSI...   \n",
      "3     ESCUELA SECUNDARIA PRIVADA MIXTA DE ORIENTE -E...   \n",
      "4                       COLEGIO EVANG√âLICO MIXTO AMIGOS   \n",
      "...                                                 ...   \n",
      "6585                            LICEO CRISTIANO ISRAEL√ç   \n",
      "6586                 LICEO INTEGRAL SANTIAGUITO -LINSA-   \n",
      "6587  ESCUELA NORMAL BILING√úE INTERCULTURAL / KITIJO...   \n",
      "6588      INSTITUTO NACIONAL DE EDUCACI√ìN DIVERSIFICADA   \n",
      "6589  ESCUELA NORMAL BILING√úE INTERCULTURAL / KITIJO...   \n",
      "\n",
      "                                       DIRECCION  TELEFONO  \\\n",
      "0                       10A. AVENIDA 3-71 ZONA 1      None   \n",
      "1         2A CALLE ENTRE 11 Y 12 AVENIDAS ZONA 1      None   \n",
      "2                   2A CALLE Y 12 AVENIDA ZONA 1      None   \n",
      "3                           2A CALLE 4-40 ZONA 1      None   \n",
      "4                       10MA AVENIDA 5-38 ZONA 1      None   \n",
      "...                                          ...       ...   \n",
      "6585                             CANT√ìN TZANJUY√ö  77217261   \n",
      "6586                            CANT√ìN PACHICHAJ  77217550   \n",
      "6587                        COMUNIDAD DE CHUKMUK  58165683   \n",
      "6588  CANTON TZANCHALI, DE LA ALDEA CERRO DE ORO  43356322   \n",
      "6589                        COMUNIDAD DE CHUKMUK  58165683   \n",
      "\n",
      "                          SUPERVISOR                       DIRECTOR  \\\n",
      "0     CESAR ADALBERTO NOGUERA JACOME     H√âCTOR ALIDIO CERON BRENES   \n",
      "1     CESAR ADALBERTO NOGUERA JACOME            ROMEO RIVERA CHAC√ìN   \n",
      "2     CESAR ADALBERTO NOGUERA JACOME       JOS√â VICENTE REYES SOL√çS   \n",
      "3     SILVIA MARILENA BUEZO MARTINEZ  ERWIN LEONEL COLINDRES MONROY   \n",
      "4     SILVIA MARILENA BUEZO MARTINEZ   ROXANA LISBETH URRUTIA PINTO   \n",
      "...                              ...                            ...   \n",
      "6585               JUAN POP CHAVAJAY             PEDRO SOSOF QUIEJ√ö   \n",
      "6586               JUAN POP CHAVAJAY            GASPAR REANDA PABLO   \n",
      "6587               JUAN POP CHAVAJAY          JOS√â MIGUEL POP TZIN√Å   \n",
      "6588          NATANAEL MORALES PACAY     DAVID ABRAHAM COTZAL BAR√ÅN   \n",
      "6589               JUAN POP CHAVAJAY          JOS√â MIGUEL POP TZIN√Å   \n",
      "\n",
      "              NIVEL  ... plan_SEMIPRESENCIAL es_publico es_rural  \\\n",
      "0     DIVERSIFICADO  ...               False          1        0   \n",
      "1     DIVERSIFICADO  ...               False          1        0   \n",
      "2     DIVERSIFICADO  ...               False          1        0   \n",
      "3     DIVERSIFICADO  ...               False          0        0   \n",
      "4     DIVERSIFICADO  ...               False          0        0   \n",
      "...             ...  ...                 ...        ...      ...   \n",
      "6585  DIVERSIFICADO  ...               False          0        0   \n",
      "6586  DIVERSIFICADO  ...               False          0        0   \n",
      "6587  DIVERSIFICADO  ...               False          1        1   \n",
      "6588  DIVERSIFICADO  ...               False          1        1   \n",
      "6589  DIVERSIFICADO  ...               False          1        1   \n",
      "\n",
      "     tiene_telefono plan_VIRTUAL A DISTANCIA plan_MIXTO area_SIN ESPECIFICAR  \\\n",
      "0                 0                      NaN        NaN                  NaN   \n",
      "1                 0                      NaN        NaN                  NaN   \n",
      "2                 0                      NaN        NaN                  NaN   \n",
      "3                 0                      NaN        NaN                  NaN   \n",
      "4                 0                      NaN        NaN                  NaN   \n",
      "...             ...                      ...        ...                  ...   \n",
      "6585              1                    False        NaN                  NaN   \n",
      "6586              1                    False        NaN                  NaN   \n",
      "6587              1                    False        NaN                  NaN   \n",
      "6588              1                    False        NaN                  NaN   \n",
      "6589              1                    False        NaN                  NaN   \n",
      "\n",
      "      plan_SABATINO plan_INTERCALADO  plan_DOMINICAL  \n",
      "0               NaN              NaN             NaN  \n",
      "1               NaN              NaN             NaN  \n",
      "2               NaN              NaN             NaN  \n",
      "3               NaN              NaN             NaN  \n",
      "4               NaN              NaN             NaN  \n",
      "...             ...              ...             ...  \n",
      "6585            NaN              NaN             NaN  \n",
      "6586            NaN              NaN             NaN  \n",
      "6587            NaN              NaN             NaN  \n",
      "6588            NaN              NaN             NaN  \n",
      "6589            NaN              NaN             NaN  \n",
      "\n",
      "[6590 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_encoded)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dd1db6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 datasets procesados\n",
      "Columnas originales: 17\n",
      "Columnas finales: 41\n",
      "Nuevas columnas creadas: 24\n",
      "RESUMEN COMPLETO DEL DATASET LIMPIO (CON COLUMNAS EXTRAS):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing (%)</th>\n",
       "      <th>unique_values</th>\n",
       "      <th>sample_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TELEFONO</td>\n",
       "      <td>25.39</td>\n",
       "      <td>3186</td>\n",
       "      <td>[78328708, 78320670, 78320556, 78323391, 58437...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CODIGO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6590</td>\n",
       "      <td>[20-01-0024-46, 20-01-0029-46, 20-01-0030-46, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DISTRITO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>620</td>\n",
       "      <td>[20-001, 20-024, 20-027, 99-001, 20-030]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MUNICIPIO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>343</td>\n",
       "      <td>[CHIQUIMULA, SAN JOSE LA ARADA, SAN JUAN ERMIT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEPARTAMENTO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23</td>\n",
       "      <td>[CHIQUIMULA, SACATEPEQUEZ, ALTA VERAPAZ, SAN M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESTABLECIMIENTO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3569</td>\n",
       "      <td>[ESCUELA DE CIENCIAS COMERCIALES NOCTURNA, INS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DIRECCION</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4428</td>\n",
       "      <td>[10A. AVENIDA 3-71 ZONA 1, 2A CALLE ENTRE 11 Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SUPERVISOR</td>\n",
       "      <td>0.00</td>\n",
       "      <td>598</td>\n",
       "      <td>[CESAR ADALBERTO NOGUERA JACOME, SILVIA MARILE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3860</td>\n",
       "      <td>[H√âCTOR ALIDIO CERON BRENES, ROMEO RIVERA CHAC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NIVEL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[DIVERSIFICADO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SECTOR</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>[OFICIAL, PRIVADO, COOPERATIVA, MUNICIPAL]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AREA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>[URBANA, RURAL, SIN ESPECIFICAR]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>STATUS</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>[ABIERTA]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MODALIDAD</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[MONOLINGUE, BILINGUE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>JORNADA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>[NOCTURNA, VESPERTINA, DOBLE, MATUTINA, SIN JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PLAN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9</td>\n",
       "      <td>[DIARIO, FIN DE SEMANA, A DISTANCIA, SEMIPRESE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DEPARTAMENTAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>[CHIQUIMULA, SACATEP√âQUEZ, ALTA VERAPAZ, SAN M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sector_COOPERATIVA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sector_MUNICIPAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sector_OFICIAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sector_PRIVADO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>area_RURAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>area_URBANA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>modalidad_BILINGUE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>modalidad_MONOLINGUE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jornada_DOBLE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jornada_INTERMEDIA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>jornada_MATUTINA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jornada_NOCTURNA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jornada_SIN JORNADA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>jornada_VESPERTINA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>plan_A DISTANCIA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>plan_DIARIO</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[True, False]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>plan_FIN DE SEMANA</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>plan_SEMIPRESENCIAL</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[False, True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>es_publico</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>es_rural</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>es_urbano</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>tiene_telefono</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tipo_establecimiento</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4</td>\n",
       "      <td>[ESCUELA_LICEO, INSTITUTO_COLEGIO, CENTRO, OTRO]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>longitud_nombre</td>\n",
       "      <td>0.00</td>\n",
       "      <td>107</td>\n",
       "      <td>[40, 62, 81, 51, 31]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  column  missing (%)  unique_values  \\\n",
       "6               TELEFONO        25.39           3186   \n",
       "0                 CODIGO         0.00           6590   \n",
       "1               DISTRITO         0.00            620   \n",
       "3              MUNICIPIO         0.00            343   \n",
       "2           DEPARTAMENTO         0.00             23   \n",
       "4        ESTABLECIMIENTO         0.00           3569   \n",
       "5              DIRECCION         0.00           4428   \n",
       "7             SUPERVISOR         0.00            598   \n",
       "8               DIRECTOR         0.00           3860   \n",
       "9                  NIVEL         0.00              1   \n",
       "10                SECTOR         0.00              4   \n",
       "11                  AREA         0.00              3   \n",
       "12                STATUS         0.00              1   \n",
       "13             MODALIDAD         0.00              2   \n",
       "14               JORNADA         0.00              6   \n",
       "15                  PLAN         0.00              9   \n",
       "16         DEPARTAMENTAL         0.00             26   \n",
       "17    sector_COOPERATIVA         0.00              2   \n",
       "18      sector_MUNICIPAL         0.00              2   \n",
       "19        sector_OFICIAL         0.00              2   \n",
       "20        sector_PRIVADO         0.00              2   \n",
       "21            area_RURAL         0.00              2   \n",
       "22           area_URBANA         0.00              2   \n",
       "23    modalidad_BILINGUE         0.00              2   \n",
       "24  modalidad_MONOLINGUE         0.00              2   \n",
       "25         jornada_DOBLE         0.00              2   \n",
       "26    jornada_INTERMEDIA         0.00              2   \n",
       "27      jornada_MATUTINA         0.00              2   \n",
       "28      jornada_NOCTURNA         0.00              2   \n",
       "29   jornada_SIN JORNADA         0.00              2   \n",
       "30    jornada_VESPERTINA         0.00              2   \n",
       "31      plan_A DISTANCIA         0.00              2   \n",
       "32           plan_DIARIO         0.00              2   \n",
       "33    plan_FIN DE SEMANA         0.00              2   \n",
       "34   plan_SEMIPRESENCIAL         0.00              2   \n",
       "35            es_publico         0.00              2   \n",
       "36              es_rural         0.00              2   \n",
       "37             es_urbano         0.00              2   \n",
       "38        tiene_telefono         0.00              2   \n",
       "39  tipo_establecimiento         0.00              4   \n",
       "40       longitud_nombre         0.00            107   \n",
       "\n",
       "                                        sample_values  \n",
       "6   [78328708, 78320670, 78320556, 78323391, 58437...  \n",
       "0   [20-01-0024-46, 20-01-0029-46, 20-01-0030-46, ...  \n",
       "1            [20-001, 20-024, 20-027, 99-001, 20-030]  \n",
       "3   [CHIQUIMULA, SAN JOSE LA ARADA, SAN JUAN ERMIT...  \n",
       "2   [CHIQUIMULA, SACATEPEQUEZ, ALTA VERAPAZ, SAN M...  \n",
       "4   [ESCUELA DE CIENCIAS COMERCIALES NOCTURNA, INS...  \n",
       "5   [10A. AVENIDA 3-71 ZONA 1, 2A CALLE ENTRE 11 Y...  \n",
       "7   [CESAR ADALBERTO NOGUERA JACOME, SILVIA MARILE...  \n",
       "8   [H√âCTOR ALIDIO CERON BRENES, ROMEO RIVERA CHAC...  \n",
       "9                                     [DIVERSIFICADO]  \n",
       "10         [OFICIAL, PRIVADO, COOPERATIVA, MUNICIPAL]  \n",
       "11                   [URBANA, RURAL, SIN ESPECIFICAR]  \n",
       "12                                          [ABIERTA]  \n",
       "13                             [MONOLINGUE, BILINGUE]  \n",
       "14  [NOCTURNA, VESPERTINA, DOBLE, MATUTINA, SIN JO...  \n",
       "15  [DIARIO, FIN DE SEMANA, A DISTANCIA, SEMIPRESE...  \n",
       "16  [CHIQUIMULA, SACATEP√âQUEZ, ALTA VERAPAZ, SAN M...  \n",
       "17                                      [False, True]  \n",
       "18                                      [False, True]  \n",
       "19                                      [True, False]  \n",
       "20                                      [False, True]  \n",
       "21                                      [False, True]  \n",
       "22                                      [True, False]  \n",
       "23                                      [False, True]  \n",
       "24                                      [True, False]  \n",
       "25                                      [False, True]  \n",
       "26                                      [False, True]  \n",
       "27                                      [False, True]  \n",
       "28                                      [True, False]  \n",
       "29                                      [False, True]  \n",
       "30                                      [False, True]  \n",
       "31                                      [False, True]  \n",
       "32                                      [True, False]  \n",
       "33                                      [False, True]  \n",
       "34                                      [False, True]  \n",
       "35                                             [1, 0]  \n",
       "36                                             [0, 1]  \n",
       "37                                             [1, 0]  \n",
       "38                                             [0, 1]  \n",
       "39   [ESCUELA_LICEO, INSTITUTO_COLEGIO, CENTRO, OTRO]  \n",
       "40                               [40, 62, 81, 51, 31]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IMPACTO DE LA LIMPIEZA:\n",
      "Total de registros: 6,590\n",
      "Tel√©fonos v√°lidos: 4,917 (74.6%)\n",
      "Establecimientos sin comillas: 6,590\n",
      "Valores √∫nicos en PLAN: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cleaned_datasets = {}\n",
    "for name, df in datasets.items():\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    df_clean['ESTABLECIMIENTO'] = df_clean['ESTABLECIMIENTO'].str.replace('\"', '', regex=False)\n",
    "    \n",
    "    df_clean['PLAN'] = df_clean['PLAN'].str.replace(r'\\s*\\([^)]*\\)', '', regex=True).str.strip()\n",
    "    \n",
    "    def clean_phone(phone):\n",
    "        if pd.isna(phone):\n",
    "            return None\n",
    "        phone_str = str(phone)\n",
    "        if '-' in phone_str:\n",
    "            phone_str = phone_str.split('-')[0]\n",
    "        numbers = re.sub(r'[^0-9]', '', phone_str)\n",
    "        if len(numbers) == 8:\n",
    "            return numbers\n",
    "        elif len(numbers) == 7 and numbers[0] in ['3', '4', '5']:\n",
    "            return '0' + numbers\n",
    "        elif len(numbers) == 7:\n",
    "            return numbers\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    df_clean['TELEFONO'] = df_clean['TELEFONO'].apply(clean_phone)\n",
    "    \n",
    "    categorical_fields = ['SECTOR', 'AREA', 'MODALIDAD', 'JORNADA', 'PLAN']\n",
    "    \n",
    "    for field in categorical_fields:\n",
    "        if field in df_clean.columns:\n",
    "            dummies = pd.get_dummies(df_clean[field], prefix=field.lower())\n",
    "            df_clean = pd.concat([df_clean, dummies], axis=1)\n",
    "    \n",
    "    df_clean['es_publico'] = df_clean['SECTOR'].isin(['OFICIAL', 'MUNICIPAL']).astype(int)\n",
    "    df_clean['es_rural'] = (df_clean['AREA'] == 'RURAL').astype(int)\n",
    "    df_clean['es_urbano'] = (df_clean['AREA'] == 'URBANA').astype(int)\n",
    "    df_clean['tiene_telefono'] = df_clean['TELEFONO'].notna().astype(int)\n",
    "    \n",
    "    def categorize_establishment(name):\n",
    "        name_upper = str(name).upper()\n",
    "        if any(word in name_upper for word in ['INSTITUTO', 'COLEGIO']):\n",
    "            return 'INSTITUTO_COLEGIO'\n",
    "        elif any(word in name_upper for word in ['ESCUELA', 'LICEO']):\n",
    "            return 'ESCUELA_LICEO'\n",
    "        elif any(word in name_upper for word in ['CENTRO', 'NUCLEO']):\n",
    "            return 'CENTRO'\n",
    "        else:\n",
    "            return 'OTRO'\n",
    "    \n",
    "    df_clean['tipo_establecimiento'] = df_clean['ESTABLECIMIENTO'].apply(categorize_establishment)\n",
    "    df_clean['longitud_nombre'] = df_clean['ESTABLECIMIENTO'].str.len()\n",
    "    \n",
    "    cleaned_datasets[name] = df_clean\n",
    "\n",
    "sample_df = list(cleaned_datasets.values())[0]\n",
    "original_cols = 17  \n",
    "new_cols = len(sample_df.columns)\n",
    "print(f\"{len(cleaned_datasets)} datasets procesados\")\n",
    "print(f\"Columnas originales: {original_cols}\")\n",
    "print(f\"Columnas finales: {new_cols}\")\n",
    "print(f\"Nuevas columnas creadas: {new_cols - original_cols}\")\n",
    "\n",
    "all_columns = list(cleaned_datasets[list(cleaned_datasets.keys())[0]].columns)\n",
    "summary_stats = []\n",
    "\n",
    "for col in all_columns:\n",
    "    col_data = []\n",
    "    for name, df in cleaned_datasets.items():\n",
    "        if col in df.columns:\n",
    "            series = df[col].astype(str).str.strip()\n",
    "            col_data.extend(series)\n",
    "\n",
    "    series_all = pd.Series(col_data)\n",
    "    n_total = len(series_all)\n",
    "    n_missing = (series_all == \"\").sum() + series_all.isna().sum() + (series_all == \"None\").sum()\n",
    "    n_unique = series_all.nunique()\n",
    "    \n",
    "    valid_values = series_all[(series_all != \"\") & (series_all.notna()) & (series_all != \"None\")]\n",
    "    sample_values = valid_values.unique()[:5].tolist() if len(valid_values) > 0 else []\n",
    "    \n",
    "    summary_stats.append({\n",
    "        \"column\": col,\n",
    "        \"missing (%)\": round((n_missing / n_total) * 100, 2),\n",
    "        \"unique_values\": n_unique,\n",
    "        \"sample_values\": sample_values\n",
    "    })\n",
    "\n",
    "df_summary_clean = pd.DataFrame(summary_stats)\n",
    "df_summary_clean.sort_values(\"missing (%)\", ascending=False, inplace=True)\n",
    "\n",
    "print(\"RESUMEN COMPLETO DEL DATASET LIMPIO (CON COLUMNAS EXTRAS):\")\n",
    "display(df_summary_clean)\n",
    "\n",
    "print(f\"\\nIMPACTO DE LA LIMPIEZA:\")\n",
    "total_records = sum(len(df) for df in cleaned_datasets.values())\n",
    "print(f\"Total de registros: {total_records:,}\")\n",
    "\n",
    "combined_clean = pd.concat(cleaned_datasets.values(), ignore_index=True)\n",
    "print(f\"Tel√©fonos v√°lidos: {combined_clean['TELEFONO'].notna().sum():,} ({combined_clean['TELEFONO'].notna().mean()*100:.1f}%)\")\n",
    "print(f\"Establecimientos sin comillas: {(~combined_clean['ESTABLECIMIENTO'].str.contains('\"', na=False)).sum():,}\")\n",
    "print(f\"Valores √∫nicos en PLAN: {combined_clean['PLAN'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
